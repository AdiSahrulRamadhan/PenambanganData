
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>1. Analisis Penelitian dan Implementasi Sistem Klasifikasi Varietas Anggur(Wine) &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="assets/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="assets/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="assets/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="assets/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="assets/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="assets/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="assets/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="assets/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="assets/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="assets/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="assets/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="assets/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="assets/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="assets/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="assets/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="assets/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="assets/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="assets/documentation_options.js?v=9eb32ce0"></script>
    <script src="assets/doctools.js?v=888ff710"></script>
    <script src="assets/sphinx_highlight.js?v=dc90522c"></script>
    <script src="assets/clipboard.min.js?v=a7894cd8"></script>
    <script src="assets/copybutton.js?v=f281be69"></script>
    <script src="assets/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="assets/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="assets/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="assets/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = '22_072_UAS_Penambangan_Data_Wine_UciDataset';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="assets/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="assets/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="22_072_UAS_Penambangan_Data_Wine_UciDataset.html">
                     Catatan UAS Individu Wine Classification Datasets
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F22_072_UAS_Penambangan_Data_Wine_UciDataset.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/22_072_UAS_Penambangan_Data_Wine_UciDataset.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>1. Analisis Penelitian dan Implementasi Sistem Klasifikasi Varietas Anggur(Wine)</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">1. Analisis Penelitian dan Implementasi Sistem Klasifikasi Varietas Anggur(Wine)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tujuan-analisis-dan-implementasi-sistem-klasifikasi-varietas-anggur-untuk-industri-pabrik-wine">Tujuan Analisis dan Implementasi Sistem Klasifikasi Varietas Anggur untuk Industri Pabrik Wine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-wine">Apa Itu Wine?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-understanding-memahami-data-kismis">2. Data Understanding / Memahami data kismis</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pengumpulan-data">Pengumpulan Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mencari-datasets">Mencari Datasets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integrasi-data">Integrasi Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengambil-dan-menampilkan-datasets">Mengambil dan Menampilkan Datasets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memahami-data">Memahami Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explore-mengetahui-kualitas-datasets-wine-dan-memahami">Explore / Mengetahui Kualitas Datasets Wine dan memahami</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jumlah-data-fitur-dan-tipe-data">Jumlah Data Fitur dan Tipe Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jumlah-data-dari-datasets-wine">Jumlah Data Dari Datasets Wine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jumlah-class-pada-data-kategori-setiap-class">Jumlah Class pada data / Kategori setiap Class</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-datasets">Deskripsi Datasets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-kualitas-data">Identifikasi Kualitas Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-data-missing-values">1. Deteksi Data Missing Values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-data-outlier">2. Deteksi Data Outlier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-duplikasi-datasets">3. Deteksi Duplikasi Datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing-data">3.Preprocessing Data</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modelling">4. Modelling</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pemilihan-model">Pemilihan Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-naive-bayes-classification">GAUSSIAN NAIVE BAYES CLASSIFICATION</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#membagi-data-train-data-test">Membagi Data Train &amp; Data Test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-train">Data Train</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-test">Data Test</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#melakukan-prediksi-dengan-bantuan-sklearn-naive-bayes">Melakukan Prediksi dengan bantuan Sklearn Naive Bayes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-akurasi-predict-data">Hasil Akurasi &amp; Predict Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-hasil-analisis-klasifikasi">Kesimpulan Hasil Analisis Klasifikasi  :</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pertemuan-baru-dengan-pengembangan-baru-model-baru">Pertemuan Baru dengan Pengembangan Baru Model Baru</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ensemble-learning">Ensemble Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking-classifier-meta-classifier">2. Stacking Classifier (Meta Classifier)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-meta-predict-classifier-model-naive-bayes-manual">A. Meta Predict Classifier Model Naive Bayes Manual</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-p1">Model P1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-p2">Model P2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menggabungkan-hasil-prediksi-2-model">Menggabungkan hasil prediksi 2 model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-stacking-dengan-scikit-learn">Implementasi stacking dengan scikit-learn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-bootstrap-aggregating">3. Bagging (Bootstrap Aggregating)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-hasil-model-yang-didapatkan">Evaluasi & Kesimpulan Hasil Model Yang Didapatkan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deployment-implementasi-model">Deployment Implementasi Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-web">Implementasi Web</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-implementasi-web">Hasil Implementasi Web</a></li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="analisis-penelitian-dan-implementasi-sistem-klasifikasi-varietas-anggur-wine">
<h1>1. Analisis Penelitian dan Implementasi Sistem Klasifikasi Varietas Anggur(Wine)<a class="headerlink" href="#analisis-penelitian-dan-implementasi-sistem-klasifikasi-varietas-anggur-wine" title="Link to this heading">#</a></h1>
<p>Link menuju website yang sudah Saya buat atau hosting :</p>
<p>Untuk Klasifikasi Gaussian Naive Bayes: <a class="reference external" href="https://adisahrul123.pythonanywhere.com/">https://adisahrul123.pythonanywhere.com/</a></p>
<img src="barugambar/image-20240621-010540.png" width="75%" align="center" /><section id="tujuan-analisis-dan-implementasi-sistem-klasifikasi-varietas-anggur-untuk-industri-pabrik-wine">
<h2>Tujuan Analisis dan Implementasi Sistem Klasifikasi Varietas Anggur untuk Industri Pabrik Wine<a class="headerlink" href="#tujuan-analisis-dan-implementasi-sistem-klasifikasi-varietas-anggur-untuk-industri-pabrik-wine" title="Link to this heading">#</a></h2>
<p>Tujuan dari penggunaan dataset “Wine” adalah untuk mengembangkan sistem klasifikasi yang akurat dan efisien guna menyortir varietas anggur secara otomatis di pabrik wine. Sistem ini akan menggunakan analisis kimiawi untuk mengidentifikasi dan mengklasifikasikan anggur ke dalam salah satu dari tiga varietas yang berbeda. Implementasi sistem klasifikasi ini diharapkan dapat memberikan manfaat sebagai berikut:</p>
<p>Berikut adalah manfaat dari penggunaan sistem klasifikasi varietas anggur untuk pabrik industri wine:</p>
<ol class="arabic simple">
<li><p>Peningkatan Efisiensi Produksi: Mengotomatisasi penyortiran anggur untuk mengurangi waktu dan tenaga kerja manual.</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p>Kontrol Kualitas Lebih Baik: Memastikan konsistensi dan kualitas produk sesuai standar varietas anggur.</p></li>
</ol>
<ol class="arabic simple" start="3">
<li><p>Autentikasi dan Pencegahan Penipuan: Mengautentikasi varietas anggur untuk menjaga kepercayaan konsumen dan integritas merek.</p></li>
</ol>
<ol class="arabic simple" start="4">
<li><p>Optimasi Proses Produksi: Menggunakan data kimia untuk mengembangkan dan meningkatkan profil rasa anggur.</p></li>
</ol>
<ol class="arabic simple" start="5">
<li><p>Penghematan Biaya: Mengurangi biaya tenaga kerja dan kesalahan manusia, serta mengurangi variabilitas produksi.</p></li>
</ol>
<p>Secara keseluruhan, tujuan dari pengembangan sistem klasifikasi varietas anggur menggunakan dataset “Wine” adalah untuk memberikan solusi teknologi yang inovatif bagi pabrik wine, meningkatkan efisiensi, kualitas, dan konsistensi produk, serta mendukung pertumbuhan bisnis melalui optimasi proses dan penghematan biaya.</p>
</section>
<section id="apa-itu-wine">
<h2>Apa Itu Wine?<a class="headerlink" href="#apa-itu-wine" title="Link to this heading">#</a></h2>
<p>Wine, atau anggur, adalah minuman beralkohol yang telah dinikmati oleh manusia selama ribuan tahun. Proses pembuatannya dimulai dengan pemilihan buah anggur yang matang. Anggur ini kemudian diperas untuk mengeluarkan jusnya. Dalam pembuatan wine merah, kulit anggur juga dibiarkan bersama jus selama fermentasi untuk memberikan warna dan karakteristik rasa yang khas.</p>
<p>Fermentasi adalah inti dari pembuatan wine, di mana ragi (yeast) mengubah gula dalam jus anggur menjadi alkohol dan karbon dioksida. Proses ini bisa berlangsung dari beberapa hari hingga beberapa minggu, tergantung pada jenis wine yang dibuat. Setelah fermentasi, wine sering kali disimpan dalam tong kayu atau tangki stainless steel untuk pematangan, yang bisa berlangsung dari beberapa bulan hingga beberapa tahun. Selama pematangan, wine mengembangkan kompleksitas rasa dan aroma.</p>
<p>Ada berbagai jenis wine, masing-masing dengan karakteristik uniknya:</p>
<ul class="simple">
<li><p>Wine Merah dibuat dari anggur merah atau hitam dengan kulitnya, memberikan warna yang kaya dan tanin.</p></li>
</ul>
<ul class="simple">
<li><p>Wine Putih biasanya dibuat dari anggur putih atau anggur merah tanpa kulit, menghasilkan minuman yang lebih ringan dan segar.</p></li>
</ul>
<ul class="simple">
<li><p>Rosé adalah wine merah yang difermentasi sebentar dengan kulit anggur, memberikan warna merah muda.</p></li>
</ul>
<ul class="simple">
<li><p>Sparkling Wine seperti Champagne, memiliki gelembung karbon dioksida alami yang memberikan sensasi berbuih.</p></li>
</ul>
<ul class="simple">
<li><p>Dessert Wine manis dengan kadar gula yang lebih tinggi, sering kali disajikan sebagai penutup.</p></li>
</ul>
<p>Wine tidak hanya sekedar minuman, tetapi juga bagian dari tradisi dan budaya di banyak negara. Setiap wilayah memiliki cara unik dalam membuat dan menikmati wine, dari kebun anggur di Prancis dan Italia hingga kilang anggur di California dan Australia. Wine juga sering kali dikaitkan dengan perayaan, makan malam istimewa, dan momen-momen penting dalam kehidupan.</p>
<p>Selain sebagai minuman sosial, wine dalam jumlah moderat diketahui memiliki beberapa manfaat kesehatan, seperti peningkatan kesehatan jantung. Namun, penting untuk mengonsumsinya dengan bijak karena konsumsi berlebihan dapat menyebabkan masalah kesehatan.</p>
<p>Secara keseluruhan, wine adalah hasil dari perpaduan antara seni dan sains, mencerminkan tradisi yang kaya dan dedikasi para pembuatnya yang selalu mencari cara untuk menciptakan rasa dan aroma yang sempurna.</p>
<p>Setelah memahami definisi wine, proses pembuatannya, serta berbagai kegunaannya dalam industri dan budaya, kita sekarang siap untuk melangkah ke tahap berikutnya dalam analisis data kita, yaitu pemahaman data (data understanding). Pada tahap ini, kita akan mendalami dataset “Wine” dari UCI Machine Learning Repository, menganalisis struktur dan konten data, mengidentifikasi pola dan karakteristik penting, serta mempersiapkan data untuk analisis lebih lanjut. Tahap ini penting untuk memastikan bahwa kita memiliki pemahaman yang mendalam dan akurat tentang data yang kita miliki sebelum melakukan proses pemodelan dan interpretasi hasil.</p>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="data-understanding-memahami-data-kismis">
<h1>2. Data Understanding / Memahami data kismis<a class="headerlink" href="#data-understanding-memahami-data-kismis" title="Link to this heading">#</a></h1>
<p>Data understanding adalah salah satu tahapan dalam proses analisis data yang bertujuan untuk memahami data yang akan diolah sebelum langkah-langkah analisis lebih lanjut dilakukan. Dalam tahap ini, fokus utamanya adalah untuk mengumpulkan informasi tentang data, mengeksplorasi karakteristiknya, dan memahami konteksnya. Pada Analisis kali ini case kita yakni memahami datasets Raisin namun sebelumnya kita harus mengambil datasets dulu supaya data itu pasti apa yang akan kita pahami dan lakukan proses klasifikasi.</p>
<section id="pengumpulan-data">
<h2>Pengumpulan Data<a class="headerlink" href="#pengumpulan-data" title="Link to this heading">#</a></h2>
<section id="mencari-datasets">
<h3>Mencari Datasets<a class="headerlink" href="#mencari-datasets" title="Link to this heading">#</a></h3>
<p>Langkah pertama pada pegumpulan data adalah dengan mencari dataset yang akan kita gunakan, sesuai penjelasan di atas kita akan menggunakan Dataset Wine yang bersumber dari UCI Datasets :</p>
<p>Sumber Datasets Wine : <a class="reference external" href="https://archive.ics.uci.edu/dataset/109/wine">https://archive.ics.uci.edu/dataset/109/wine</a></p>
</section>
<section id="integrasi-data">
<h3>Integrasi Data<a class="headerlink" href="#integrasi-data" title="Link to this heading">#</a></h3>
<p>untuk mengambil data agar dapat diolah, perlu untuk penginstallan package yang telah disediakan oleh UCI Dataset. Instalasi dilakukan berguna untuk menarik data yang berasal dari UCI dataset agar dapat diolah. peritah untuk mengambil data dari UCI dataset dapat di lihat ketika kita menekan tombol import in python pada datase yang kita inginkan dan kita perlu mengikuti perintah tersebut agar data dapat diambil dari UCI dataset.</p>
<p>Berikut Ketika file code import  in python nya jadi kita bisa mencopynya dan bisa lanjut untuk proses mengambil datasets dan menampilkannya dari code import in python tersebut itu.</p>
<img src="barugambar/image-20240626-140419.png" width="" align="" /></section>
<section id="mengambil-dan-menampilkan-datasets">
<h3>Mengambil dan Menampilkan Datasets<a class="headerlink" href="#mengambil-dan-menampilkan-datasets" title="Link to this heading">#</a></h3>
<p>Setelah mengambil code import nya langkah selanjutnya yakni menampilkan atau mengambil datasets tersebut.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>ucimlrepo
<span class="kn">from</span> <span class="nn">ucimlrepo</span> <span class="kn">import</span> <span class="n">fetch_ucirepo</span> 

<span class="c1"># Mengambil dataset Wine dari UCI Repository</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span>

<span class="c1"># Menampilkan metadata dataset</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Metadata:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">wine</span><span class="o">.</span><span class="n">metadata</span><span class="p">)</span>

<span class="c1"># Menampilkan informasi variabel (fitur dan target)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Informasi Variabel:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">wine</span><span class="o">.</span><span class="n">variables</span><span class="p">)</span>

<span class="c1"># Memisahkan fitur (X) dan target (y)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>

<span class="c1"># Contoh untuk menunjukkan bagaimana mengakses X dan y:</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Contoh data fitur (X):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Contoh data target (y):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: ucimlrepo in c:\users\adi sahrul r\appdata\local\programs\python\python312\lib\site-packages (0.0.6)
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEPRECATION: Loading egg at c:\users\adi sahrul r\appdata\local\programs\python\python312\lib\site-packages\nmslib-2.1.2-py3.12-win-amd64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Metadata:
{&#39;uci_id&#39;: 109, &#39;name&#39;: &#39;Wine&#39;, &#39;repository_url&#39;: &#39;https://archive.ics.uci.edu/dataset/109/wine&#39;, &#39;data_url&#39;: &#39;https://archive.ics.uci.edu/static/public/109/data.csv&#39;, &#39;abstract&#39;: &#39;Using chemical analysis to determine the origin of wines&#39;, &#39;area&#39;: &#39;Physics and Chemistry&#39;, &#39;tasks&#39;: [&#39;Classification&#39;], &#39;characteristics&#39;: [&#39;Tabular&#39;], &#39;num_instances&#39;: 178, &#39;num_features&#39;: 13, &#39;feature_types&#39;: [&#39;Integer&#39;, &#39;Real&#39;], &#39;demographics&#39;: [], &#39;target_col&#39;: [&#39;class&#39;], &#39;index_col&#39;: None, &#39;has_missing_values&#39;: &#39;no&#39;, &#39;missing_values_symbol&#39;: None, &#39;year_of_dataset_creation&#39;: 1992, &#39;last_updated&#39;: &#39;Mon Aug 28 2023&#39;, &#39;dataset_doi&#39;: &#39;10.24432/C5PC7J&#39;, &#39;creators&#39;: [&#39;Stefan Aeberhard&#39;, &#39;M. Forina&#39;], &#39;intro_paper&#39;: {&#39;title&#39;: &#39;Comparative analysis of statistical pattern recognition methods in high dimensional settings&#39;, &#39;authors&#39;: &#39;S. Aeberhard, D. Coomans, O. Vel&#39;, &#39;published_in&#39;: &#39;Pattern Recognition&#39;, &#39;year&#39;: 1994, &#39;url&#39;: &#39;https://www.semanticscholar.org/paper/83dc3e4030d7b9fbdbb4bde03ce12ab70ca10528&#39;, &#39;doi&#39;: &#39;10.1016/0031-3203(94)90145-7&#39;}, &#39;additional_info&#39;: {&#39;summary&#39;: &#39;These data are the results of a chemical analysis of wines grown in the same region in Italy but derived from three different cultivars. The analysis determined the quantities of 13 constituents found in each of the three types of wines. \r\n\r\nI think that the initial data set had around 30 variables, but for some reason I only have the 13 dimensional version. I had a list of what the 30 or so variables were, but a.)  I lost it, and b.), I would not know which 13 variables are included in the set.\r\n\r\nThe attributes are (dontated by Riccardo Leardi, riclea@anchem.unige.it )\r\n1) Alcohol\r\n2) Malic acid\r\n3) Ash\r\n4) Alcalinity of ash  \r\n5) Magnesium\r\n6) Total phenols\r\n7) Flavanoids\r\n8) Nonflavanoid phenols\r\n9) Proanthocyanins\r\n10)Color intensity\r\n11)Hue\r\n12)OD280/OD315 of diluted wines\r\n13)Proline \r\n\r\nIn a classification context, this is a well posed problem with &quot;well behaved&quot; class structures. A good data set for first testing of a new classifier, but not very challenging.           &#39;, &#39;purpose&#39;: &#39;test&#39;, &#39;funded_by&#39;: None, &#39;instances_represent&#39;: None, &#39;recommended_data_splits&#39;: None, &#39;sensitive_data&#39;: None, &#39;preprocessing_description&#39;: None, &#39;variable_info&#39;: &#39;All attributes are continuous\r\n\t\r\nNo statistics available, but suggest to standardise variables for certain uses (e.g. for us with classifiers which are NOT scale invariant)\r\n\r\nNOTE: 1st attribute is class identifier (1-3)&#39;, &#39;citation&#39;: None}}

Informasi Variabel:
                            name     role         type demographic  \
0                          class   Target  Categorical        None   
1                        Alcohol  Feature   Continuous        None   
2                      Malicacid  Feature   Continuous        None   
3                            Ash  Feature   Continuous        None   
4              Alcalinity_of_ash  Feature   Continuous        None   
5                      Magnesium  Feature      Integer        None   
6                  Total_phenols  Feature   Continuous        None   
7                     Flavanoids  Feature   Continuous        None   
8           Nonflavanoid_phenols  Feature   Continuous        None   
9                Proanthocyanins  Feature   Continuous        None   
10               Color_intensity  Feature   Continuous        None   
11                           Hue  Feature   Continuous        None   
12  0D280_0D315_of_diluted_wines  Feature   Continuous        None   
13                       Proline  Feature      Integer        None   

   description units missing_values  
0         None  None             no  
1         None  None             no  
2         None  None             no  
3         None  None             no  
4         None  None             no  
5         None  None             no  
6         None  None             no  
7         None  None             no  
8         None  None             no  
9         None  None             no  
10        None  None             no  
11        None  None             no  
12        None  None             no  
13        None  None             no  

Contoh data fitur (X):
   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \
0    14.23       1.71  2.43               15.6        127           2.80   
1    13.20       1.78  2.14               11.2        100           2.65   
2    13.16       2.36  2.67               18.6        101           2.80   
3    14.37       1.95  2.50               16.8        113           3.85   
4    13.24       2.59  2.87               21.0        118           2.80   

   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \
0        3.06                  0.28             2.29             5.64  1.04   
1        2.76                  0.26             1.28             4.38  1.05   
2        3.24                  0.30             2.81             5.68  1.03   
3        3.49                  0.24             2.18             7.80  0.86   
4        2.69                  0.39             1.82             4.32  1.04   

   0D280_0D315_of_diluted_wines  Proline  
0                          3.92     1065  
1                          3.40     1050  
2                          3.17     1185  
3                          3.45     1480  
4                          2.93      735  

Contoh data target (y):
   class
0      1
1      1
2      1
3      1
4      1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ucimlrepo</span> <span class="kn">import</span> <span class="n">fetch_ucirepo</span> 
  
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span> 
  
<span class="c1"># data (as pandas dataframes) </span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span> 
<span class="n">y</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span> 

<span class="n">df_wine</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="n">df_wine</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;wine.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1">#variable features</span>
<span class="nb">print</span><span class="p">(</span><span class="n">df_wine</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \
0      14.23       1.71  2.43               15.6        127           2.80   
1      13.20       1.78  2.14               11.2        100           2.65   
2      13.16       2.36  2.67               18.6        101           2.80   
3      14.37       1.95  2.50               16.8        113           3.85   
4      13.24       2.59  2.87               21.0        118           2.80   
..       ...        ...   ...                ...        ...            ...   
173    13.71       5.65  2.45               20.5         95           1.68   
174    13.40       3.91  2.48               23.0        102           1.80   
175    13.27       4.28  2.26               20.0        120           1.59   
176    13.17       2.59  2.37               20.0        120           1.65   
177    14.13       4.10  2.74               24.5         96           2.05   

     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \
0          3.06                  0.28             2.29             5.64  1.04   
1          2.76                  0.26             1.28             4.38  1.05   
2          3.24                  0.30             2.81             5.68  1.03   
3          3.49                  0.24             2.18             7.80  0.86   
4          2.69                  0.39             1.82             4.32  1.04   
..          ...                   ...              ...              ...   ...   
173        0.61                  0.52             1.06             7.70  0.64   
174        0.75                  0.43             1.41             7.30  0.70   
175        0.69                  0.43             1.35            10.20  0.59   
176        0.68                  0.53             1.46             9.30  0.60   
177        0.76                  0.56             1.35             9.20  0.61   

     0D280_0D315_of_diluted_wines  Proline  class  
0                            3.92     1065      1  
1                            3.40     1050      1  
2                            3.17     1185      1  
3                            3.45     1480      1  
4                            2.93      735      1  
..                            ...      ...    ...  
173                          1.74      740      3  
174                          1.56      750      3  
175                          1.56      835      3  
176                          1.62      840      3  
177                          1.60      560      3  

[178 rows x 14 columns]
</pre></div>
</div>
</div>
</div>
<p>Jadi, kode tersebut digunakan untuk mengambil dataset “Wine” dari UCI Machine Learning Repository, memisahkan fitur-fiturnya dan target variabelnya, menggabungkannya menjadi satu DataFrame, menyimpan DataFrame tersebut ke dalam file CSV, dan mencetak DataFrame tersebut. Data diatas akan kita gunakan untuk Analisis Kasus kali ini, maka sebelum kita melakukan proses selanjutnya kita harus memahami datasets tersebut di mana tujuannya adalah untuk mengklasifikasikan sampel anggur menjadi salah satu dari beberapa varietas. Dataset ini secara khusus dapat digunakan untuk mengidentifikasi varietas anggur berdasarkan beberapa fitur kimia yang terkait dengan setiap jenis anggur.</p>
</section>
<section id="memahami-data">
<h3>Memahami Data<a class="headerlink" href="#memahami-data" title="Link to this heading">#</a></h3>
<p>Deskripsi Penjelasan datasets, Dataset “Wine” dari UCI Machine Learning Repository terdiri dari 178 instance dengan 13 atribut input yang mencakup Alcohol, Malic acid, Ash, Alcalinity of ash, Magnesium, Total phenols, Flavanoids, Nonflavanoid phenols, Proanthocyanins, Color intensity, Hue, OD280/OD315 of diluted wines, dan Proline. Atribut-atribut ini adalah data numerik dalam bentuk floating point, yang mencerminkan berbagai komponen kimia dalam wine yang dapat mempengaruhi karakteristik sensorik dan kualitasnya. Selain itu, terdapat satu atribut output kategorikal, yaitu Class, yang memiliki tiga nilai kelas: 1, 2, atau 3, mewakili varietas anggur yang berbeda. Dataset ini dikumpulkan oleh Riccardo Leardi (<a class="reference external" href="mailto:riclea&#37;&#52;&#48;anchem&#46;unige&#46;it">riclea<span>&#64;</span>anchem<span>&#46;</span>unige<span>&#46;</span>it</a>) dan biasanya digunakan untuk tujuan klasifikasi, di mana tujuan utamanya adalah untuk mengembangkan model machine learning yang dapat mengenali dan membedakan varietas anggur berdasarkan profil kimia yang terukur. Atribut-atribut yang terdapat dalam dataset ini meliputi:</p>
<p>Fitur-fitur Dan Class Datasets:</p>
<ol class="arabic simple">
<li><p>Alcohol:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Persentase volume alkohol dalam wine. Alkohol adalah komponen utama yang berkontribusi pada kekuatan dan karakteristik sensorik wine. Tingkat alkohol yang tepat dapat mempengaruhi rasa, aroma, dan keseimbangan keseluruhan wine.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Malic acid:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Konsentrasi asam malat, salah satu asam organik utama dalam anggur. Asam malat memberikan rasa asam atau tajam pada wine. Selama proses fermentasi malolaktik, asam malat dapat diubah menjadi asam laktat yang lebih lembut, mengurangi keasaman dan menciptakan wine yang lebih lembut.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Ash:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Jumlah abu yang tersisa setelah pembakaran anggur. Ini mengindikasikan kandungan mineral dalam wine. Kandungan abu yang tepat dapat mempengaruhi rasa dan kestabilan wine.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Alcalinity of ash:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Tingkat kealkalian abu, mengukur kapasitas basa dalam wine. Tingkat kealkalian yang tinggi dapat mempengaruhi pH wine dan akhirnya mempengaruhi rasa serta umur simpan wine.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>Magnesium:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Kandungan magnesium dalam wine, yang merupakan mineral penting. Magnesium berperan dalam proses fermentasi dan dapat mempengaruhi rasa serta kestabilan wine.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Integer)</p></li>
</ul>
<ol class="arabic simple" start="6">
<li><p>Total phenols:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Jumlah keseluruhan fenol dalam wine. Fenol adalah senyawa yang berkontribusi pada rasa, warna, dan sifat antioksidan wine. Total fenol mencakup flavonoid dan nonflavonoid fenol.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="7">
<li><p>Flavanoids:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Jumlah flavonoid, sekelompok senyawa fenolik yang mempengaruhi warna, rasa, dan sifat antioksidan wine. Flavonoid juga berperan dalam astringensi dan umur simpan wine.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="8">
<li><p>Nonflavanoid phenols:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Jumlah fenol nonflavonoid dalam wine. Fenol nonflavonoid juga mempengaruhi rasa dan karakteristik sensorik wine, meskipun dalam kadar yang berbeda dibandingkan flavonoid.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="9">
<li><p>Proanthocyanins:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Jumlah proantosianidin, senyawa fenolik yang berkontribusi pada warna dan astringensi wine. Proantosianidin berasal dari kulit, biji, dan batang anggur.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="10">
<li><p>Color intensity:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Intensitas warna wine, yang diukur berdasarkan kegelapan warna wine. Intensitas warna dapat memberikan indikasi tentang kekayaan fenol dan umur wine.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="11">
<li><p>Hue:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Hue atau rona warna wine, yang menggambarkan kualitas dan nuansa warna wine. Hue memberikan informasi tentang kondisi penuaan dan proses oksidasi wine.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="12">
<li><p>OD280/OD315 of diluted wines:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Rasio penyerapan ultraviolet pada panjang gelombang 280 nm dan 315 nm. Rasio ini merupakan indikator jumlah fenol dalam wine dan sering digunakan untuk menilai kualitas wine.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="13">
<li><p>Proline:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Kandungan proline, asam amino yang berkontribusi pada aroma dan rasa wine. Proline juga berperan dalam reaksi Maillard selama penuaan, yang mempengaruhi karakteristik aroma dan rasa.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Numerik (Continues)</p></li>
</ul>
<ol class="arabic simple" start="14">
<li><p>Class:</p></li>
</ol>
<ul class="simple">
<li><p>Deskripsi: Kategori atau jenis wine yang menunjukkan varietas wine. Angka 1, 2, dan 3 masing-masing mewakili tiga varietas anggur yang berbeda dari wilayah yang sama di Italia.</p></li>
</ul>
<ul class="simple">
<li><p>Tipe Data: Kategorikal (Integer)</p></li>
</ul>
<p>Perbedaan &amp; Penjelasan 3 Kategorikal Varietas Wine:</p>
<p>Varietas pertama: dalam dataset ini menonjol dengan kandungan alkohol yang lebih tinggi serta jumlah fenol dan flavonoid yang signifikan. Wine dari varietas ini cenderung memiliki rasa yang kuat dan kompleks, dengan aroma yang kaya dan tekstur yang mendalam. Kandungan fenol yang tinggi memberikan wine warna yang lebih dalam dan tajam, sementara alkohol yang lebih tinggi memberikan kesan struktural yang kuat. Perbedaan ini menunjukkan bahwa varietas pertama ini sering kali dianggap sebagai yang paling berani dan penuh karakter di antara ketiga varietas, dengan ciri khas yang mendalam dan berlapis-lapis dalam setiap tegukan.</p>
<p>Varietas kedua: ditandai dengan tingkat keasaman yang lebih tinggi, karena konsentrasi malic acid yang signifikan. Wine dari varietas ini biasanya lebih segar dengan rasa yang tajam dan menyegarkan. Meskipun memiliki kandungan fenol yang sedikit lebih rendah dibandingkan varietas pertama, varietas kedua tetap memberikan kompleksitas yang menarik, dengan nuansa buah yang lebih cerah dan keasaman yang seimbang.</p>
<p>Varietas ketiga: menonjol dengan kandungan mineral seperti magnesium dan proline yang lebih tinggi. Hal ini menciptakan wine dengan aroma yang lebih kompleks dan rasa yang lebih halus serta seimbang. Wine dari varietas ini sering kali memiliki karakteristik aroma yang unik, dengan sentuhan mineral dan buah yang terintegrasi secara elegan. Perbedaan ini menunjukkan bahwa varietas ketiga menawarkan pengalaman sensorik yang berbeda, dengan fokus pada keseimbangan dan kompleksitas rasa yang menyeluruh.</p>
<p>Secara keseluruhan, ketiga varietas anggur ini memberikan kontribusi unik pada spektrum rasa dan aroma wine, mencerminkan perbedaan dalam komposisi kimia mereka yang mempengaruhi karakteristik akhir dari wine yang dihasilkan. Pemahaman mendalam tentang perbedaan ini penting untuk mengenali dan mengapresiasi berbagai varietas wine serta memahami bagaimana mereka dapat dipilah dan dianalisis dalam konteks industri wine.</p>
</section>
</section>
<section id="explore-mengetahui-kualitas-datasets-wine-dan-memahami">
<h2>Explore / Mengetahui Kualitas Datasets Wine dan memahami<a class="headerlink" href="#explore-mengetahui-kualitas-datasets-wine-dan-memahami" title="Link to this heading">#</a></h2>
<p>Dari Explore data wine yang kita dapatkan informasi mengenai tiga varietas anggur yang berasal dari wilayah yang sama di Italia. Setiap dataset terdiri dari 178 instance dengan 13 atribut input yang mencakup berbagai komponen kimia seperti Alcohol, Malic acid, dan Flavanoids. Atribut-atribut ini berupa data numerik dalam bentuk floating point yang merepresentasikan karakteristik kimia dari masing-masing sample wine. Selain itu, terdapat satu atribut output kategorikal, yaitu Class, yang memiliki tiga nilai kelas: 1, 2, atau 3, yang mengidentifikasi varietas anggur yang berbeda. Setelah kita menampilkan data dan mengetahui Penjelasan dari pemahaman fitur dari datasets tersebut kita bisa menampilkan Lebih secara rinci informasi atau pemahaman dari dataset Wine tersebut. selanjutnya untuk memahami dan mengetahui lebih dalam, kita detail kan untuk Spesifikasi atau fitur dan Class yang ada pada datasets, seperti mengetahui tipe data nya, mengetahui jumlah data nya, jumlah fitur dan classnya. Dibawah ini adalah Spesifikasi Detail dari datasets.</p>
<section id="jumlah-data-fitur-dan-tipe-data">
<h3>Jumlah Data Fitur dan Tipe Data<a class="headerlink" href="#jumlah-data-fitur-dan-tipe-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_wine</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 178 entries, 0 to 177
Data columns (total 14 columns):
 #   Column                        Non-Null Count  Dtype  
---  ------                        --------------  -----  
 0   Alcohol                       178 non-null    float64
 1   Malicacid                     178 non-null    float64
 2   Ash                           178 non-null    float64
 3   Alcalinity_of_ash             178 non-null    float64
 4   Magnesium                     178 non-null    int64  
 5   Total_phenols                 178 non-null    float64
 6   Flavanoids                    178 non-null    float64
 7   Nonflavanoid_phenols          178 non-null    float64
 8   Proanthocyanins               178 non-null    float64
 9   Color_intensity               178 non-null    float64
 10  Hue                           178 non-null    float64
 11  0D280_0D315_of_diluted_wines  178 non-null    float64
 12  Proline                       178 non-null    int64  
 13  class                         178 non-null    int64  
dtypes: float64(11), int64(3)
memory usage: 19.6 KB
</pre></div>
</div>
</div>
</div>
<p>Bisa kita ketahui dari hasil output code tersebut dalam datasets terdapat 178 data masing-masing 13 Features dan 1 Class disana juga mengecek tipedata dari setiap Kolom atau fiturnya.</p>
</section>
<section id="jumlah-data-dari-datasets-wine">
<h3>Jumlah Data Dari Datasets Wine<a class="headerlink" href="#jumlah-data-dari-datasets-wine" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">num_data</span> <span class="o">=</span> <span class="n">df_wine</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah data dalam dataset Wine:&quot;</span><span class="p">,</span> <span class="n">num_data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah data dalam dataset Wine: 178
</pre></div>
</div>
</div>
</div>
<p>Diatas sudah bisa kita ketahui bahwa datasets record nya sebanyak 178 data.</p>
</section>
<section id="jumlah-class-pada-data-kategori-setiap-class">
<h3>Jumlah Class pada data / Kategori setiap Class<a class="headerlink" href="#jumlah-class-pada-data-kategori-setiap-class" title="Link to this heading">#</a></h3>
<p>Jadi kita melakukan pengecekan terhadap data Wine berpakah masing masing Class atau kategori dari 3 Kategori yakni Class 1, Class 2, dan Class 3. Dibawah ini adalah code untuk menampilkannya.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df_wine</span><span class="o">.</span><span class="n">groupby</span><span class="p">(</span><span class="s1">&#39;class&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>class
1    59
2    71
3    48
dtype: int64
</pre></div>
</div>
</div>
</div>
<p>Seperti hasil output diatas menghasilkan masing-masing Class Kategorinya menghasilkan data per Kategorinya.</p>
<ol class="arabic simple">
<li><p>Class 1 = 59 Data Record .</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p>Class 2= 71 Data Record.</p></li>
</ol>
<ol class="arabic simple" start="3">
<li><p>Class 3= 48 Data Record.</p></li>
</ol>
</section>
<section id="deskripsi-datasets">
<h3>Deskripsi Datasets<a class="headerlink" href="#deskripsi-datasets" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Deskripsi Dari Datasets Wine</span>
<span class="n">des</span> <span class="o">=</span> <span class="n">df_wine</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Deskripsi Data Wine:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">des</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Deskripsi Data Wine:
          Alcohol   Malicacid         Ash  Alcalinity_of_ash   Magnesium  \
count  178.000000  178.000000  178.000000         178.000000  178.000000   
mean    13.000618    2.336348    2.366517          19.494944   99.741573   
std      0.811827    1.117146    0.274344           3.339564   14.282484   
min     11.030000    0.740000    1.360000          10.600000   70.000000   
25%     12.362500    1.602500    2.210000          17.200000   88.000000   
50%     13.050000    1.865000    2.360000          19.500000   98.000000   
75%     13.677500    3.082500    2.557500          21.500000  107.000000   
max     14.830000    5.800000    3.230000          30.000000  162.000000   

       Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \
count     178.000000  178.000000            178.000000       178.000000   
mean        2.295112    2.029270              0.361854         1.590899   
std         0.625851    0.998859              0.124453         0.572359   
min         0.980000    0.340000              0.130000         0.410000   
25%         1.742500    1.205000              0.270000         1.250000   
50%         2.355000    2.135000              0.340000         1.555000   
75%         2.800000    2.875000              0.437500         1.950000   
max         3.880000    5.080000              0.660000         3.580000   

       Color_intensity         Hue  0D280_0D315_of_diluted_wines      Proline  \
count       178.000000  178.000000                    178.000000   178.000000   
mean          5.058090    0.957449                      2.611685   746.893258   
std           2.318286    0.228572                      0.709990   314.907474   
min           1.280000    0.480000                      1.270000   278.000000   
25%           3.220000    0.782500                      1.937500   500.500000   
50%           4.690000    0.965000                      2.780000   673.500000   
75%           6.200000    1.120000                      3.170000   985.000000   
max          13.000000    1.710000                      4.000000  1680.000000   

            class  
count  178.000000  
mean     1.938202  
std      0.775035  
min      1.000000  
25%      1.000000  
50%      2.000000  
75%      3.000000  
max      3.000000  
</pre></div>
</div>
</div>
</div>
<p>Kode diatas Menunjukkan deskripsi atau  rangkuman statistik deskriptif dari DataFrame dibawah ini penjelasan detailnya :</p>
<ol class="arabic simple">
<li><p>Count: Menunjukkan jumlah entri non-null untuk setiap kolom. Semua kolom memiliki 178 entri.</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p>Mean: Merupakan nilai rata-rata dari setiap kolom.</p></li>
</ol>
<ul class="simple">
<li><p>Alcohol: 13.000618</p></li>
</ul>
<ul class="simple">
<li><p>Malicacid: 2.336348</p></li>
</ul>
<ul class="simple">
<li><p>Ash: 2.366517</p></li>
</ul>
<ul class="simple">
<li><p>Alcalinity_of_ash: 19.494944</p></li>
</ul>
<ul class="simple">
<li><p>Magnesium: 99.741573</p></li>
</ul>
<ul class="simple">
<li><p>Total_phenols: 2.295112</p></li>
</ul>
<ul class="simple">
<li><p>Flavanoids: 2.029270</p></li>
</ul>
<ul class="simple">
<li><p>Nonflavanoid_phenols: 0.361854</p></li>
</ul>
<ul class="simple">
<li><p>Proanthocyanins: 1.590899</p></li>
</ul>
<ul class="simple">
<li><p>Color_intensity: 5.058090</p></li>
</ul>
<ul class="simple">
<li><p>Hue: 0.957449</p></li>
</ul>
<ul class="simple">
<li><p>0D280_0D315_of_diluted_wines: 2.611685</p></li>
</ul>
<ul class="simple">
<li><p>Proline: 746.893258</p></li>
</ul>
<ul class="simple">
<li><p>class: 1.938202</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Std (Standard Deviation): Menunjukkan seberapa jauh data tersebar dari nilai rata-rata.</p></li>
</ol>
<ul class="simple">
<li><p>Alcohol: 0.811827</p></li>
</ul>
<ul class="simple">
<li><p>Malicacid: 1.117146</p></li>
</ul>
<ul class="simple">
<li><p>Ash: 0.274344</p></li>
</ul>
<ul class="simple">
<li><p>Alcalinity_of_ash: 3.339564</p></li>
</ul>
<ul class="simple">
<li><p>Magnesium: 14.282484</p></li>
</ul>
<ul class="simple">
<li><p>Total_phenols: 0.625851</p></li>
</ul>
<ul class="simple">
<li><p>Flavanoids: 0.998859</p></li>
</ul>
<ul class="simple">
<li><p>Nonflavanoid_phenols: 0.124453</p></li>
</ul>
<ul class="simple">
<li><p>Proanthocyanins: 0.572359</p></li>
</ul>
<ul class="simple">
<li><p>Color_intensity: 2.318286</p></li>
</ul>
<ul class="simple">
<li><p>Hue: 0.228572</p></li>
</ul>
<ul class="simple">
<li><p>0D280_0D315_of_diluted_wines: 0.709990</p></li>
</ul>
<ul class="simple">
<li><p>Proline: 314.907474</p></li>
</ul>
<ul class="simple">
<li><p>class: 0.775035</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>Min (Minimum): Nilai minimum dalam setiap kolom.</p></li>
</ol>
<ul class="simple">
<li><p>Alcohol: 11.03</p></li>
</ul>
<ul class="simple">
<li><p>Malicacid: 0.74</p></li>
</ul>
<ul class="simple">
<li><p>Ash: 1.36</p></li>
</ul>
<ul class="simple">
<li><p>Alcalinity_of_ash: 10.6</p></li>
</ul>
<ul class="simple">
<li><p>Magnesium: 70.0</p></li>
</ul>
<ul class="simple">
<li><p>Total_phenols: 0.98</p></li>
</ul>
<ul class="simple">
<li><p>Flavanoids: 0.34</p></li>
</ul>
<ul class="simple">
<li><p>Nonflavanoid_phenols: 0.13</p></li>
</ul>
<ul class="simple">
<li><p>Proanthocyanins: 0.41</p></li>
</ul>
<ul class="simple">
<li><p>Color_intensity: 1.28</p></li>
</ul>
<ul class="simple">
<li><p>Hue: 0.48</p></li>
</ul>
<ul class="simple">
<li><p>0D280_0D315_of_diluted_wines: 1.27</p></li>
</ul>
<ul class="simple">
<li><p>Proline: 278.0</p></li>
</ul>
<ul class="simple">
<li><p>class: 1.0</p></li>
</ul>
<ol class="arabic simple" start="5">
<li><p>25th Percentile (Q1): Nilai yang membagi data menjadi dua bagian, di mana 25% data berada di bawah nilai ini.</p></li>
</ol>
<ul class="simple">
<li><p>Alcohol: 12.3625</p></li>
</ul>
<ul class="simple">
<li><p>Malicacid: 1.6025</p></li>
</ul>
<ul class="simple">
<li><p>Ash: 2.21</p></li>
</ul>
<ul class="simple">
<li><p>Alcalinity_of_ash: 17.2</p></li>
</ul>
<ul class="simple">
<li><p>Magnesium: 88.0</p></li>
</ul>
<ul class="simple">
<li><p>Total_phenols: 1.7425</p></li>
</ul>
<ul class="simple">
<li><p>Flavanoids: 1.205</p></li>
</ul>
<ul class="simple">
<li><p>Nonflavanoid_phenols: 0.27</p></li>
</ul>
<ul class="simple">
<li><p>Proanthocyanins: 1.25</p></li>
</ul>
<ul class="simple">
<li><p>Color_intensity: 3.22</p></li>
</ul>
<ul class="simple">
<li><p>Hue: 0.7825</p></li>
</ul>
<ul class="simple">
<li><p>0D280_0D315_of_diluted_wines: 1.9375</p></li>
</ul>
<ul class="simple">
<li><p>Proline: 500.5</p></li>
</ul>
<ul class="simple">
<li><p>class: 1.0</p></li>
</ul>
<ol class="arabic simple" start="6">
<li><p>50th Percentile (Median/Q2): Nilai yang membagi data menjadi dua bagian yang sama besar, juga dikenal sebagai median.</p></li>
</ol>
<ul class="simple">
<li><p>Alcohol: 13.05</p></li>
</ul>
<ul class="simple">
<li><p>Malicacid: 1.865</p></li>
</ul>
<ul class="simple">
<li><p>Ash: 2.36</p></li>
</ul>
<ul class="simple">
<li><p>Alcalinity_of_ash: 19.5</p></li>
</ul>
<ul class="simple">
<li><p>Magnesium: 98.0</p></li>
</ul>
<ul class="simple">
<li><p>Total_phenols: 2.355</p></li>
</ul>
<ul class="simple">
<li><p>Flavanoids: 2.135</p></li>
</ul>
<ul class="simple">
<li><p>Nonflavanoid_phenols: 0.34</p></li>
</ul>
<ul class="simple">
<li><p>Proanthocyanins: 1.555</p></li>
</ul>
<ul class="simple">
<li><p>Color_intensity: 4.69</p></li>
</ul>
<ul class="simple">
<li><p>Hue: 0.965</p></li>
</ul>
<ul class="simple">
<li><p>0D280_0D315_of_diluted_wines: 2.78</p></li>
</ul>
<ul class="simple">
<li><p>Proline: 673.5</p></li>
</ul>
<ul class="simple">
<li><p>class: 2.0</p></li>
</ul>
<ol class="arabic simple" start="7">
<li><p>75th Percentile (Q3): Nilai yang membagi data menjadi dua bagian, di mana 75% data berada di bawah nilai ini.</p></li>
</ol>
<ul class="simple">
<li><p>Alcohol: 13.6775</p></li>
</ul>
<ul class="simple">
<li><p>Malicacid: 3.0825</p></li>
</ul>
<ul class="simple">
<li><p>Ash: 2.5575</p></li>
</ul>
<ul class="simple">
<li><p>Alcalinity_of_ash: 21.5</p></li>
</ul>
<ul class="simple">
<li><p>Magnesium: 107.0</p></li>
</ul>
<ul class="simple">
<li><p>Total_phenols: 2.8</p></li>
</ul>
<ul class="simple">
<li><p>Flavanoids: 2.875</p></li>
</ul>
<ul class="simple">
<li><p>Nonflavanoid_phenols: 0.4375</p></li>
</ul>
<ul class="simple">
<li><p>Proanthocyanins: 1.95</p></li>
</ul>
<ul class="simple">
<li><p>Color_intensity: 6.2</p></li>
</ul>
<ul class="simple">
<li><p>Hue: 1.12</p></li>
</ul>
<ul class="simple">
<li><p>0D280_0D315_of_diluted_wines: 3.17</p></li>
</ul>
<ul class="simple">
<li><p>Proline: 985.0</p></li>
</ul>
<ul class="simple">
<li><p>class: 3.0</p></li>
</ul>
<ol class="arabic simple" start="8">
<li><p>Max (Maximum): Nilai maksimum dalam setiap kolom.</p></li>
</ol>
<ul class="simple">
<li><p>Alcohol: 14.83</p></li>
</ul>
<ul class="simple">
<li><p>Malicacid: 5.8</p></li>
</ul>
<ul class="simple">
<li><p>Ash: 3.23</p></li>
</ul>
<ul class="simple">
<li><p>Alcalinity_of_ash: 30.0</p></li>
</ul>
<ul class="simple">
<li><p>Magnesium: 162.0</p></li>
</ul>
<ul class="simple">
<li><p>Total_phenols: 3.88</p></li>
</ul>
<ul class="simple">
<li><p>Flavanoids: 5.08</p></li>
</ul>
<ul class="simple">
<li><p>Nonflavanoid_phenols: 0.66</p></li>
</ul>
<ul class="simple">
<li><p>Proanthocyanins: 3.58</p></li>
</ul>
<ul class="simple">
<li><p>Color_intensity: 13.0</p></li>
</ul>
<ul class="simple">
<li><p>Hue: 1.71</p></li>
</ul>
<ul class="simple">
<li><p>0D280_0D315_of_diluted_wines: 4.0</p></li>
</ul>
<ul class="simple">
<li><p>Proline: 1680.0</p></li>
</ul>
<ul class="simple">
<li><p>class: 3.0</p></li>
</ul>
<p>Ini adalah rangkuman statistik deskriptif untuk setiap kolom dalam dataset wine. Dengan informasi ini, Kita dapat memahami distribusi dan variasi nilai-nilai dalam dataset tersebut. Selanjutnya kita bisa ke tahap Identifikasi Kualitas Data Wine.</p>
</section>
</section>
<section id="identifikasi-kualitas-data">
<h2>Identifikasi Kualitas Data<a class="headerlink" href="#identifikasi-kualitas-data" title="Link to this heading">#</a></h2>
<p>Identifikasi data ada beberapa tahap yakni mulai dari pengecekan atau deteksi data tersebut apakah terdapat Data Duplikat, Missing Value, dan Outlier.Jika terdapat duplikasi data maka kita bisa menghapusnya. Jika terdapat missing value kita juga dapat melakukan proses imputasi data yang null atau missing dengan beberapa metode yakni metode Knn dan Mean. Lalu Tahap selanjutnya kita melakukan Deteksi Outlier jika terdapat data outlier yang terlalu jauh. Meskipun terdeteksi adanya
outlier namun model dianggap dapat
mengakomodasinya sehingga outlier tidak
dihilangkan. Maka dibawah ini urutan tahapan Preprocessing Data :</p>
<ol class="arabic simple">
<li><p>Deteksi Data Missing Values</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p>Deteksi Data Outlier</p></li>
</ol>
<ol class="arabic simple" start="3">
<li><p>Deteksi Duplikasi Data</p></li>
</ol>
<section id="deteksi-data-missing-values">
<h3>1. Deteksi Data Missing Values<a class="headerlink" href="#deteksi-data-missing-values" title="Link to this heading">#</a></h3>
<p>Code dibawah ini melakukan pengecekan apakah terdapat data missing values dan dimunculkan jumlahnya masing-masing disetiap fiturnya.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Melakukan pengecekan apakah terdapat missing value dalam setiap kolom</span>
<span class="n">missing_val</span> <span class="o">=</span> <span class="n">df_wine</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>

<span class="c1"># Menampilkan berapa jumlah adanya missing value untuk setiap kolomnya</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Jumlah nilai yang hilang untuk setiap kolom:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">missing_val</span><span class="p">)</span>

<span class="c1"># Melakukan pengecekan apakah ada nilai null atau missing value</span>
<span class="k">if</span> <span class="n">missing_val</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Tidak ada missing value.&quot;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Terdapat missing value dalam dataset.&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Jumlah nilai yang hilang untuk setiap kolom:
Alcohol                         0
Malicacid                       0
Ash                             0
Alcalinity_of_ash               0
Magnesium                       0
Total_phenols                   0
Flavanoids                      0
Nonflavanoid_phenols            0
Proanthocyanins                 0
Color_intensity                 0
Hue                             0
0D280_0D315_of_diluted_wines    0
Proline                         0
class                           0
dtype: int64
Tidak ada missing value.
</pre></div>
</div>
</div>
</div>
<p>Berdasarkan hasil pengecekan yang telah dilakukan, kita dapat menyimpulkan bahwa tidak ada nilai yang hilang dalam data Wine. Dengan demikian, kita tidak perlu melakukan proses imputasi atau penanganan missing value.</p>
<p>Berikut adalah beberapa implikasi dari kesimpulan ini:</p>
<ol class="arabic simple">
<li><p>Pengolahan Data Lebih Mudah:</p></li>
</ol>
<ul class="simple">
<li><p>Tanpa missing value, kita dapat langsung melanjutkan ke tahap preprocessing lainnya seperti normalisasi atau standarisasi data tanpa perlu khawatir mengenai imputasi.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Analisis yang Lebih Akurat:</p></li>
</ol>
<ul class="simple">
<li><p>Data yang lengkap dan utuh akan memberikan hasil analisis yang lebih akurat karena tidak ada informasi yang hilang yang perlu diestimasi atau diisi.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Penghematan Waktu:</p></li>
</ol>
<ul class="simple">
<li><p>Tanpa perlu melakukan imputasi missing value, kita dapat menghemat waktu dan sumber daya dalam tahap persiapan data.</p></li>
</ul>
</section>
<section id="deteksi-data-outlier">
<h3>2. Deteksi Data Outlier<a class="headerlink" href="#deteksi-data-outlier" title="Link to this heading">#</a></h3>
<p>Outlier atau pencilan adalah data dalam dataset yang menyimpang secara signifikan dari data lainnya. Mendeteksi outlier penting untuk memastikan bahwa data yang kita olah menghasilkan model yang akurat dan andal. Outlier dapat mempengaruhi hasil analisis dan model prediksi, sehingga identifikasinya menjadi langkah krusial dalam proses pemrosesan data.</p>
<p>Salah satu metode yang dapat digunakan untuk mengidentifikasi outlier adalah Local Outlier Factor (LOF). LOF adalah algoritma yang mengukur kelainan data dengan membandingkan kepadatan lokalnya terhadap data tetangga. Data dengan nilai LOF tinggi dianggap sebagai outlier karena memiliki kepadatan yang jauh lebih rendah dibandingkan data sekitarnya.</p>
<p>Proses penerapan LOF melibatkan beberapa langkah, mulai dari memilih parameter yang tepat, seperti jumlah tetangga (k), hingga menghitung skor LOF untuk setiap data point dalam dataset. Skor ini kemudian digunakan untuk menentukan data mana yang dianggap sebagai outlier.</p>
<p>Menggunakan LOF, kita dapat menangani outlier dengan lebih efektif, baik dengan mengecualikan data tersebut dari analisis lebih lanjut, melakukan transformasi, atau menggunakan metode lain yang sesuai dengan tujuan analisis kita. Dengan demikian, data yang kita olah menjadi lebih bersih dan model yang dihasilkan dapat memiliki performa yang lebih baik. Dibawah ini Saya jelaskan Konsep untuk LOF Supaya mudah udah dipahami</p>
<p>Konsep Local Outlier Factor:</p>
<p>Outlier adalah titik data yang berbeda atau jauh dari titik data lainnya. Local Outlier Factor (LOF) adalah algoritma yang mengidentifikasi outlier yang ada dalam kumpulan data. Ketika suatu titik dianggap sebagai outlier berdasarkan lingkungan lokalnya, maka titik tersebut disebut local outlier . LOF akan mengidentifikasi outlier dengan mempertimbangkan kepadatan lingkungan. LOF bekerja dengan baik ketika kepadatan data tidak sama di seluruh kumpulan data. Untuk memahami LOF, kita harus mempelajari beberapa konsep secara berurutan:</p>
<ul class="simple">
<li><p>K-distance dan K-neighbors</p></li>
</ul>
<ul class="simple">
<li><p>Reachability Distance (RD)</p></li>
</ul>
<ul class="simple">
<li><p>Local Reachability Density (LRD)</p></li>
</ul>
<ul class="simple">
<li><p>Local Outlier Factor (LOF)</p></li>
</ul>
<p>K-distance dan K-neighbors</p>
<img src="barugambar/image-20240626-133454.png" width="50%" align="center" /><p>K-distance adalah jarak antara suatu titik dan tetangga ke-K terdekatnya. Tetangga ke-K yang dilambangkan dengan 𝑁𝑘(𝐴)N k(A), mencakup himpunan titik yang terletak di dalam atau pada lingkaran dengan jari-jari sebesar jarak ke-K tersebut. Himpunan ini bisa terdiri dari lebih banyak titik dibandingkan nilai K itu sendiri.</p>
<p>Sebagai contoh, mari kita ambil empat titik A, B, C, dan D. Jika 𝐾=2, maka tetangga ke-2 dari A (atau 𝑁2(𝐴)N 2(A)) adalah C, B, dan D. Dalam contoh ini, meskipun 𝐾=2, kita memiliki tiga tetangga dalam himpunan 𝑁2(𝐴)N 2(A), yaitu ∣∣𝑁2(𝐴)∣∣=3∣∣N 2 (A)∣∣=3. Dengan demikian, jumlah tetangga ke-K (∣∣𝑁𝑘(𝑡𝑖𝑡𝑖𝑘)∣∣∣∣N k (titik)∣∣) akan selalu lebih besar atau sama dengan K.</p>
<p>Memahami konsep K-distance dan tetangga ke-K ini sangat penting dalam penerapan algoritma Local Outlier Factor (LOF) karena algoritma ini mengandalkan hubungan dan kepadatan data di sekitar titik yang dianalisis. Dengan mengukur kepadatan lokal relatif terhadap tetangga-tetangga ini, LOF dapat mengidentifikasi apakah suatu titik merupakan outlier atau tidak.</p>
<p>Reachability distance (RD):</p>
<img src="barugambar/image-20240626-133911.png" width="" align="" /><img src="barugambar/image-20240626-134026.png" width="" align="" /><p>Ini didefinisikan sebagai jarak K maksimum Xj dan jarak antara Xi dan Xj. Ukuran jarak bersifat khusus untuk masalah (Euclidean, Manhattan, dll.) Dalam istilah awam, jika titik Xi terletak di dalam K-tetangga Xj, maka jarak jangkauannya adalah K-jarak Xj (garis biru), jika tidak, jarak jangkauannya adalah jarak antara Xi dan Xj (garis oranye).</p>
<p>Local reachability density (LRD)</p>
<img src="barugambar/image-20240626-134159.png" width="" align="" /><p>LRD merupakan kebalikan dari rata-rata jarak jangkauan A dari tetangganya. Semakin besar jarak jangkauan rata-rata (yaitu, tetangga jauh dari titik tersebut), semakin sedikit kepadatan titik yang ada di sekitar titik tertentu. Ini menunjukkan seberapa jauh suatu titik dari kelompok titik terdekat. Nilai LRD yang rendah menunjukkan bahwa cluster terdekat berada jauh dari titik.</p>
<p>Disini Kita Menggunakan Metode LOF untuk mendeteksi adanya outlier tidak pada setiap kolom fitur pada  dataset Wine.</p>
<p>Local Outlier Factor (LOF):</p>
<p>LRD tiap titik digunakan untuk membandingkan dengan rata-rata LRD K tetangganya. LOF adalah perbandingan rata-rata LRD K tetangga A terhadap LRD A. Jika suatu titik bukan merupakan pencilan (inlier), rasio rata-rata LRD tetangganya kira-kira sama dengan LRD suatu titik (karena kepadatan suatu titik dan tetangganya kira-kira sama). Dalam hal ini, LOF hampir sama dengan 1. Sebaliknya, jika suatu titik merupakan outlier, LRD suatu titik lebih kecil dari rata-rata LRD tetangganya. Maka nilai LOF akan tinggi. Umumnya jika LOF &gt; 1 maka dianggap outlier, namun hal tersebut tidak selalu benar. Katakanlah kita mengetahui bahwa kita hanya memiliki satu outlier dalam data, lalu kita ambil nilai LOF maksimum di antara semua nilai LOF, dan titik yang sesuai dengan nilai LOF maksimum akan dianggap sebagai outlier.</p>
<ul class="simple">
<li><p>LOF adalah metode yang mengukur kepadatan lokal dari titik data untuk menentukan seberapa jauh titik tersebut dari tetangganya. Ini sangat efektif dalam mendeteksi outlier dalam dataset yang memiliki kluster atau distribusi yang kompleks.</p></li>
</ul>
<ul class="simple">
<li><p>LOF menggunakan parameter n_neighbors untuk menentukan berapa banyak tetangga yang akan digunakan untuk menghitung kepadatan lokal, dan contamination untuk menentukan proporsi outlier dalam dataset.</p></li>
</ul>
<p>Berikut Code dibawah ini melakukan pengecekan apakah terdapat data outlier dan dimunculkan jumlahnya masing-masing di setiap fiturnya.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">LocalOutlierFactor</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">ucimlrepo</span> <span class="kn">import</span> <span class="n">fetch_ucirepo</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># Fetch dataset directly from UCIML repository</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span>

<span class="c1"># Extract features and targets</span>
<span class="n">wine_features</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">wine_targets</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>

<span class="c1"># Define feature names and target name</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">wine_features</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">target_name</span> <span class="o">=</span> <span class="s2">&quot;class&quot;</span>

<span class="c1"># Create DataFrame from features and target</span>
<span class="n">df_wine</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">wine_features</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">wine_targets</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span> <span class="o">+</span> <span class="p">[</span><span class="n">target_name</span><span class="p">])</span>

<span class="c1"># Create LOF model</span>
<span class="n">lof</span> <span class="o">=</span> <span class="n">LocalOutlierFactor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">contamination</span><span class="o">=</span><span class="mf">0.013</span><span class="p">)</span>

<span class="c1"># Predict outliers for each numeric feature</span>
<span class="n">outlier_indices</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">:</span>
    <span class="c1"># Get feature values</span>
    <span class="n">feature_values</span> <span class="o">=</span> <span class="n">df_wine</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Predict outliers</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">lof</span><span class="o">.</span><span class="n">fit_predict</span><span class="p">(</span><span class="n">feature_values</span><span class="p">)</span>
    <span class="c1"># Add outlier indices to the list</span>
    <span class="n">outlier_indices</span><span class="o">.</span><span class="n">extend</span><span class="p">([(</span><span class="n">i</span><span class="p">,</span> <span class="n">column</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="k">if</span> <span class="n">label</span> <span class="o">==</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="c1"># Remove duplicate outlier indices</span>
<span class="n">outlier_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">outlier_indices</span><span class="p">))</span>

<span class="c1"># Display found outlier indices</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;OUTLIER&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outlier_indices</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Outlier ditemukan pada baris =&gt; </span><span class="si">{</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">, pada kolom fitur =&gt; </span><span class="si">{</span><span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Collect row indices that contain outliers</span>
<span class="n">outlier_row_indices</span> <span class="o">=</span> <span class="p">[</span><span class="n">index</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">outlier_indices</span><span class="p">]</span>

<span class="c1"># Display data on rows containing outliers</span>
<span class="n">outlier_data</span> <span class="o">=</span> <span class="n">df_wine</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">outlier_row_indices</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;DATA&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data pada baris yang mengandung outlier:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">outlier_data</span><span class="p">)</span>

<span class="c1"># Assume you have ground truth labels for outliers</span>
<span class="c1"># For example, in this list, value 1 indicates an outlier, and 0 indicates not an outlier</span>
<span class="n">ground_truth_labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outlier_row_indices</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_wine</span><span class="p">))]</span>

<span class="c1"># Generate outlier predictions based on outlier_row_indices</span>
<span class="n">predicted_labels</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span> <span class="k">if</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outlier_row_indices</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_wine</span><span class="p">))]</span>

<span class="c1"># Calculate precision</span>
<span class="n">precision</span> <span class="o">=</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">ground_truth_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;PRECISION&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Precision: </span><span class="si">{</span><span class="n">precision</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Visualize outliers for each numeric feature</span>
<span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">feature_names</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df_wine</span><span class="p">[</span><span class="n">column</span><span class="p">])),</span> <span class="n">df_wine</span><span class="p">[</span><span class="n">column</span><span class="p">],</span> <span class="n">label</span><span class="o">=</span><span class="n">column</span><span class="p">)</span>
    <span class="n">outlier_indices_for_column</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outlier_indices</span> <span class="k">if</span> <span class="n">i</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">column</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">outlier_indices_for_column</span><span class="p">,</span> <span class="n">df_wine</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">outlier_indices_for_column</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Outlier&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Index&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Outlier Detection for </span><span class="si">{</span><span class="n">column</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>OUTLIER
Outlier ditemukan pada baris =&gt; 123, pada kolom fitur =&gt; Malicacid
Outlier ditemukan pada baris =&gt; 115, pada kolom fitur =&gt; Alcohol
Outlier ditemukan pada baris =&gt; 119, pada kolom fitur =&gt; Color_intensity
Outlier ditemukan pada baris =&gt; 25, pada kolom fitur =&gt; Ash
Outlier ditemukan pada baris =&gt; 146, pada kolom fitur =&gt; Total_phenols
Outlier ditemukan pada baris =&gt; 95, pada kolom fitur =&gt; Proanthocyanins
Outlier ditemukan pada baris =&gt; 95, pada kolom fitur =&gt; Magnesium
Outlier ditemukan pada baris =&gt; 22, pada kolom fitur =&gt; 0D280_0D315_of_diluted_wines
Outlier ditemukan pada baris =&gt; 13, pada kolom fitur =&gt; Alcalinity_of_ash
Outlier ditemukan pada baris =&gt; 173, pada kolom fitur =&gt; Malicacid
Outlier ditemukan pada baris =&gt; 13, pada kolom fitur =&gt; Alcohol
Outlier ditemukan pada baris =&gt; 121, pada kolom fitur =&gt; Ash
Outlier ditemukan pada baris =&gt; 146, pada kolom fitur =&gt; Flavanoids
Outlier ditemukan pada baris =&gt; 0, pada kolom fitur =&gt; 0D280_0D315_of_diluted_wines
Outlier ditemukan pada baris =&gt; 59, pada kolom fitur =&gt; Alcalinity_of_ash
Outlier ditemukan pada baris =&gt; 24, pada kolom fitur =&gt; 0D280_0D315_of_diluted_wines
Outlier ditemukan pada baris =&gt; 158, pada kolom fitur =&gt; Color_intensity
Outlier ditemukan pada baris =&gt; 115, pada kolom fitur =&gt; Hue
Outlier ditemukan pada baris =&gt; 18, pada kolom fitur =&gt; Flavanoids
Outlier ditemukan pada baris =&gt; 14, pada kolom fitur =&gt; Proline
Outlier ditemukan pada baris =&gt; 80, pada kolom fitur =&gt; Proline
Outlier ditemukan pada baris =&gt; 64, pada kolom fitur =&gt; Hue
Outlier ditemukan pada baris =&gt; 1, pada kolom fitur =&gt; Alcalinity_of_ash
Outlier ditemukan pada baris =&gt; 8, pada kolom fitur =&gt; Alcohol
Outlier ditemukan pada baris =&gt; 59, pada kolom fitur =&gt; Ash
Outlier ditemukan pada baris =&gt; 52, pada kolom fitur =&gt; Total_phenols
Outlier ditemukan pada baris =&gt; 121, pada kolom fitur =&gt; Flavanoids
Outlier ditemukan pada baris =&gt; 74, pada kolom fitur =&gt; Nonflavanoid_phenols
Outlier ditemukan pada baris =&gt; 96, pada kolom fitur =&gt; Nonflavanoid_phenols
Outlier ditemukan pada baris =&gt; 137, pada kolom fitur =&gt; Malicacid
Outlier ditemukan pada baris =&gt; 99, pada kolom fitur =&gt; Hue
Outlier ditemukan pada baris =&gt; 18, pada kolom fitur =&gt; Proline
Outlier ditemukan pada baris =&gt; 60, pada kolom fitur =&gt; Proanthocyanins
Outlier ditemukan pada baris =&gt; 89, pada kolom fitur =&gt; Magnesium
Outlier ditemukan pada baris =&gt; 3, pada kolom fitur =&gt; Total_phenols
Outlier ditemukan pada baris =&gt; 69, pada kolom fitur =&gt; Magnesium
Outlier ditemukan pada baris =&gt; 69, pada kolom fitur =&gt; Nonflavanoid_phenols
Outlier ditemukan pada baris =&gt; 110, pada kolom fitur =&gt; Proanthocyanins
Outlier ditemukan pada baris =&gt; 159, pada kolom fitur =&gt; Color_intensity
DATA
Data pada baris yang mengandung outlier:
     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \
123    13.05       5.80  2.13               21.5       86.0           2.62   
115    11.03       1.51  2.20               21.5       85.0           2.46   
119    12.00       3.43  2.00               19.0       87.0           2.00   
25     13.05       2.05  3.22               25.0      124.0           2.63   
146    13.88       5.04  2.23               20.0       80.0           0.98   
95     12.47       1.52  2.20               19.0      162.0           2.50   
95     12.47       1.52  2.20               19.0      162.0           2.50   
22     13.71       1.86  2.36               16.6      101.0           2.61   
13     14.75       1.73  2.39               11.4       91.0           3.10   
173    13.71       5.65  2.45               20.5       95.0           1.68   
13     14.75       1.73  2.39               11.4       91.0           3.10   
121    11.56       2.05  3.23               28.5      119.0           3.18   
146    13.88       5.04  2.23               20.0       80.0           0.98   
0      14.23       1.71  2.43               15.6      127.0           2.80   
59     12.37       0.94  1.36               10.6       88.0           1.98   
24     13.50       1.81  2.61               20.0       96.0           2.53   
158    14.34       1.68  2.70               25.0       98.0           2.80   
115    11.03       1.51  2.20               21.5       85.0           2.46   
18     14.19       1.59  2.48               16.5      108.0           3.30   
14     14.38       1.87  2.38               12.0      102.0           3.30   
80     12.00       0.92  2.00               19.0       86.0           2.42   
64     12.17       1.45  2.53               19.0      104.0           1.89   
1      13.20       1.78  2.14               11.2      100.0           2.65   
8      14.83       1.64  2.17               14.0       97.0           2.80   
59     12.37       0.94  1.36               10.6       88.0           1.98   
52     13.82       1.75  2.42               14.0      111.0           3.88   
121    11.56       2.05  3.23               28.5      119.0           3.18   
74     11.96       1.09  2.30               21.0      101.0           3.38   
96     11.81       2.12  2.74               21.5      134.0           1.60   
137    12.53       5.51  2.64               25.0       96.0           1.79   
99     12.29       3.17  2.21               18.0       88.0           2.85   
18     14.19       1.59  2.48               16.5      108.0           3.30   
60     12.33       1.10  2.28               16.0      101.0           2.05   
89     12.08       1.33  2.30               23.6       70.0           2.20   
3      14.37       1.95  2.50               16.8      113.0           3.85   
69     12.21       1.19  1.75               16.8      151.0           1.85   
69     12.21       1.19  1.75               16.8      151.0           1.85   
110    11.46       3.74  1.82               19.5      107.0           3.18   
159    13.48       1.67  2.64               22.5       89.0           2.60   

     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \
123        2.65                  0.30             2.01             2.60  0.73   
115        2.17                  0.52             2.01             1.90  1.71   
119        1.64                  0.37             1.87             1.28  0.93   
25         2.68                  0.47             1.92             3.58  1.13   
146        0.34                  0.40             0.68             4.90  0.58   
95         2.27                  0.32             3.28             2.60  1.16   
95         2.27                  0.32             3.28             2.60  1.16   
22         2.88                  0.27             1.69             3.80  1.11   
13         3.69                  0.43             2.81             5.40  1.25   
173        0.61                  0.52             1.06             7.70  0.64   
13         3.69                  0.43             2.81             5.40  1.25   
121        5.08                  0.47             1.87             6.00  0.93   
146        0.34                  0.40             0.68             4.90  0.58   
0          3.06                  0.28             2.29             5.64  1.04   
59         0.57                  0.28             0.42             1.95  1.05   
24         2.61                  0.28             1.66             3.52  1.12   
158        1.31                  0.53             2.70            13.00  0.57   
115        2.17                  0.52             2.01             1.90  1.71   
18         3.93                  0.32             1.86             8.70  1.23   
14         3.64                  0.29             2.96             7.50  1.20   
80         2.26                  0.30             1.43             2.50  1.38   
64         1.75                  0.45             1.03             2.95  1.45   
1          2.76                  0.26             1.28             4.38  1.05   
8          2.98                  0.29             1.98             5.20  1.08   
59         0.57                  0.28             0.42             1.95  1.05   
52         3.74                  0.32             1.87             7.05  1.01   
121        5.08                  0.47             1.87             6.00  0.93   
74         2.14                  0.13             1.65             3.21  0.99   
96         0.99                  0.14             1.56             2.50  0.95   
137        0.60                  0.63             1.10             5.00  0.82   
99         2.99                  0.45             2.81             2.30  1.42   
18         3.93                  0.32             1.86             8.70  1.23   
60         1.09                  0.63             0.41             3.27  1.25   
89         1.59                  0.42             1.38             1.74  1.07   
3          3.49                  0.24             2.18             7.80  0.86   
69         1.28                  0.14             2.50             2.85  1.28   
69         1.28                  0.14             2.50             2.85  1.28   
110        2.58                  0.24             3.58             2.90  0.75   
159        1.10                  0.52             2.29            11.75  0.57   

     0D280_0D315_of_diluted_wines  Proline  class  
123                          3.10    380.0    2.0  
115                          2.87    407.0    2.0  
119                          3.05    564.0    2.0  
25                           3.20    830.0    1.0  
146                          1.33    415.0    3.0  
95                           2.63    937.0    2.0  
95                           2.63    937.0    2.0  
22                           4.00   1035.0    1.0  
13                           2.73   1150.0    1.0  
173                          1.74    740.0    3.0  
13                           2.73   1150.0    1.0  
121                          3.69    465.0    2.0  
146                          1.33    415.0    3.0  
0                            3.92   1065.0    1.0  
59                           1.82    520.0    2.0  
24                           3.82    845.0    1.0  
158                          1.96    660.0    3.0  
115                          2.87    407.0    2.0  
18                           2.82   1680.0    1.0  
14                           3.00   1547.0    1.0  
80                           3.12    278.0    2.0  
64                           2.23    355.0    2.0  
1                            3.40   1050.0    1.0  
8                            2.85   1045.0    1.0  
59                           1.82    520.0    2.0  
52                           3.26   1190.0    1.0  
121                          3.69    465.0    2.0  
74                           3.13    886.0    2.0  
96                           2.26    625.0    2.0  
137                          1.69    515.0    3.0  
99                           2.83    406.0    2.0  
18                           2.82   1680.0    1.0  
60                           1.67    680.0    2.0  
89                           3.21    625.0    2.0  
3                            3.45   1480.0    1.0  
69                           3.07    718.0    2.0  
69                           3.07    718.0    2.0  
110                          2.81    562.0    2.0  
159                          1.78    620.0    3.0  
PRECISION
Precision: 1.0
</pre></div>
</div>
<img alt="_images/4ae3ff4b3c28a96e6fa6ebd8d82b99ef8e9741a36a85d4ed34c5160201a016e1.png" src="_images/4ae3ff4b3c28a96e6fa6ebd8d82b99ef8e9741a36a85d4ed34c5160201a016e1.png" />
<img alt="_images/921e9d07d99939843f44d531c83f170d2d2d2e73fc376059c4dff04ffd31d7c8.png" src="_images/921e9d07d99939843f44d531c83f170d2d2d2e73fc376059c4dff04ffd31d7c8.png" />
<img alt="_images/59cae0e1b322357492ab56bd3bd080cd3dd398691ddefd7e8a112eb22b2484e5.png" src="_images/59cae0e1b322357492ab56bd3bd080cd3dd398691ddefd7e8a112eb22b2484e5.png" />
<img alt="_images/8faee2184cafbb0af4632a9833ca6b8af3c53c1ac60ec74a94bdd312f2d07466.png" src="_images/8faee2184cafbb0af4632a9833ca6b8af3c53c1ac60ec74a94bdd312f2d07466.png" />
<img alt="_images/e8f2fb8d744101ed86b75245ef6d3fadd8e4d97ce27e61086e135d0c46c73ea9.png" src="_images/e8f2fb8d744101ed86b75245ef6d3fadd8e4d97ce27e61086e135d0c46c73ea9.png" />
<img alt="_images/142b03efbf18667a542829540390337f845255ea6e3bac509d12112a08250cfd.png" src="_images/142b03efbf18667a542829540390337f845255ea6e3bac509d12112a08250cfd.png" />
<img alt="_images/df443eb19c561408ba573e33e71fcdc5fee14fef6a8507b609eee648548fe9ae.png" src="_images/df443eb19c561408ba573e33e71fcdc5fee14fef6a8507b609eee648548fe9ae.png" />
<img alt="_images/4b992e6c18871bcfe03f899502136c74a1254223dfa06794d585d6cf83b2e592.png" src="_images/4b992e6c18871bcfe03f899502136c74a1254223dfa06794d585d6cf83b2e592.png" />
<img alt="_images/e5c634ecf85ae9f71c0a6af9a6521e089da112eecb9acd2339dc1f8be8ba8b7d.png" src="_images/e5c634ecf85ae9f71c0a6af9a6521e089da112eecb9acd2339dc1f8be8ba8b7d.png" />
<img alt="_images/d17fe8a9d619ff5e3caa102068b7b628f8072664a4ae549a1c45638c5fc124e0.png" src="_images/d17fe8a9d619ff5e3caa102068b7b628f8072664a4ae549a1c45638c5fc124e0.png" />
<img alt="_images/361292ae33e3ee83820d065580ea897752dd2b396a83079e0a65c00ff6dd557a.png" src="_images/361292ae33e3ee83820d065580ea897752dd2b396a83079e0a65c00ff6dd557a.png" />
<img alt="_images/9c31e24887075af87c90dcbeb0558ef4576d69650fc673a3583605d9710b2262.png" src="_images/9c31e24887075af87c90dcbeb0558ef4576d69650fc673a3583605d9710b2262.png" />
<img alt="_images/3fa65b3c611049949fce703dae0076551323c3bfc6d10d17610111c48f108eed.png" src="_images/3fa65b3c611049949fce703dae0076551323c3bfc6d10d17610111c48f108eed.png" />
</div>
</div>
<p>Untuk penanganan outlier tidak kita lakukan dikarenakan data yang terindikasi outlier masih berada di rentang 1-10 (tidak melebihi interval), lalu untuk akurasi pendeteksian outlier memiliki akurasi nilai 1.0 atau 100% yang bisa dikatakan sempurna untuk pengecekan outlier.</p>
</section>
<section id="deteksi-duplikasi-datasets">
<h3>3. Deteksi Duplikasi Datasets<a class="headerlink" href="#deteksi-duplikasi-datasets" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">duplicates</span> <span class="o">=</span> <span class="n">df_wine</span><span class="o">.</span><span class="n">duplicated</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data yang Duplikat:&quot;</span><span class="p">,</span> <span class="n">duplicates</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data yang Duplikat: 0
</pre></div>
</div>
</div>
</div>
<p>Seperti hasil output diatas sudah kita deteksi bahwa tidak adanya duplikasi data, bisa dipastikan bahwa kualitas atas identifikasi data sudah bisa dikatakan baik jadi selanjutnya kita bisa melanjutkan ke tahap Preprocessing Data.</p>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="preprocessing-data">
<h1>3.Preprocessing Data<a class="headerlink" href="#preprocessing-data" title="Link to this heading">#</a></h1>
<p>Pada proses klasifikasi perlu dilakukan
pengolahan data awal terlebih dahulu atau biasa
disebut preprocessing data. Pada Identifikasi diatas kita  mendeteksi missing value (telah dilakukan diatas) dan diketahui
pada dataset tidak terdapat data yang kosong. Kemudian tahap berikutnya adalah
mendeteksi outlier. Meskipun terdeteksi adanya
outlier namun model dianggap dapat
mengakomodasinya sehingga outlier tidak
dihilangkan.</p>
<p>Jadi dari hasil identifikasi sebelumnya kita sudah mengetahuinya tidak adanya proses preprocessing data karena data sudah kita identifikasi bahwa data tidak ada terdapat missing value dan outlier tidak perlu dihapus karena masih terakomodasi untuk menentukan kategori class Wine. Maka kita tidak perlu melakukan proses imputasi karena tidak adanya missing value dan outlier tidak perlu dihapus langsung saja kita ke tahap Modelling untuk menentukan kategori dari pengelompokan class Wine jadi tentunya kita menggunakan Metode Klasifikasi. Dibawah ini.</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="modelling">
<h1>4. Modelling<a class="headerlink" href="#modelling" title="Link to this heading">#</a></h1>
<p>Proses modelling dalam analisis data adalah langkah penting di mana Anda menggunakan berbagai teknik statistik atau algoritma machine learning untuk memahami, menganalisis, dan/atau memprediksi pola dalam data. Dikarenakan dalam Case Datasets Wine ini tujuannya untuk menentukan kategori dari pengelompokan Class Wine jadi tentunya kita menggunakan Metode Klasifikasi.</p>
<section id="pemilihan-model">
<h2>Pemilihan Model<a class="headerlink" href="#pemilihan-model" title="Link to this heading">#</a></h2>
<p>Metode Klasifikasi adalah teknik dalam analisis data yang digunakan untuk memisahkan atau mengelompokkan data ke dalam kategori atau kelas berdasarkan atribut-atribut yang ada. Tujuannya adalah untuk membangun model yang dapat memprediksi kelas atau label dari data yang tidak terlihat sebelumnya berdasarkan fitur-fitur yang diamati. Disini kita menggunakan Metode Klasifikasi Naive Bayes dikarenakan cocok digunakan untuk klasifikasi teks dan memiliki kinerja yang baik dalam dataset dengan dimensi tinggi. Kita Langsung saja Implementasikan.</p>
</section>
<section id="gaussian-naive-bayes-classification">
<h2>GAUSSIAN NAIVE BAYES CLASSIFICATION<a class="headerlink" href="#gaussian-naive-bayes-classification" title="Link to this heading">#</a></h2>
<p>Gaussian Naive Bayes merupakan sebuah teknik klasifikasi yang digunakan dalam machine learning dengan menggunakan metode probability dan Distribusi Gaussian atau Distiribusi Normal. Gaussian Distribution mengasumsikan bahwa setiap feature pada data memiliki penngaruh yang independent dalam memprediksi target. Kombinasi prediksi dari seluruh parameter adalah prediksi akhir dengan probability dari target variable yang diklasifikasikan ke dalam dua kelas. Klasifikasi akhirnya adalah hasil probability yang lebih tinggi dari grup target maka itu adalah kelas dari suatu data.</p>
<section id="membagi-data-train-data-test">
<h3>Membagi Data Train &amp; Data Test<a class="headerlink" href="#membagi-data-train-data-test" title="Link to this heading">#</a></h3>
<p>Dalam perbandingan studi kasus kita membagi datanya 80% Data Train sedangkan Data Testnya 20%. Hal ini dilakukan agar saat kita melakukan prediksi terhadap data baru, kita mendapat hasil yang lebih efektif. Dan apakah hasil tersebut tepat maka kita langsung saja membagi data tersebut lalu melakukan proses klasifikasi dengan metode NaiveBayes Prediksi dengan bantuan Sklearn Modelling Naives Bayes.</p>
</section>
<section id="data-train">
<h3>Data Train<a class="headerlink" href="#data-train" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">ucimlrepo</span> <span class="kn">import</span> <span class="n">fetch_ucirepo</span>

<span class="c1"># Fetch dataset directly from UCIML repository</span>
<span class="n">wine</span> <span class="o">=</span> <span class="n">fetch_ucirepo</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="mi">109</span><span class="p">)</span>

<span class="c1"># Extract features and targets</span>
<span class="n">wine_features</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">features</span>
<span class="n">wine_targets</span> <span class="o">=</span> <span class="n">wine</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">targets</span>

<span class="c1"># Define feature names and target name</span>
<span class="n">feature_names</span> <span class="o">=</span> <span class="n">wine_features</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">target_name</span> <span class="o">=</span> <span class="s2">&quot;class&quot;</span>

<span class="c1"># Create DataFrame from features and target</span>
<span class="n">df_wine</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">wine_features</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="n">wine_targets</span><span class="o">.</span><span class="n">values</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))),</span> <span class="n">columns</span><span class="o">=</span><span class="n">feature_names</span> <span class="o">+</span> <span class="p">[</span><span class="n">target_name</span><span class="p">])</span>

<span class="c1"># Define features and target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_wine</span><span class="p">[</span><span class="n">feature_names</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_wine</span><span class="p">[</span><span class="n">target_name</span><span class="p">]</span>

<span class="c1"># Membagi dataset menjadi data latih &amp; data uji</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Combine training features and target into a single DataFrame</span>
<span class="n">trained</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">trained</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Wine_train.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training dataset (jumlah data: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">trained</span><span class="p">)</span><span class="si">}</span><span class="s2">):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">trained</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training dataset (jumlah data: 142):
     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \
158    14.34       1.68  2.70               25.0       98.0           2.80   
137    12.53       5.51  2.64               25.0       96.0           1.79   
98     12.37       1.07  2.10               18.5       88.0           3.52   
159    13.48       1.67  2.64               22.5       89.0           2.60   
38     13.07       1.50  2.10               15.5       98.0           2.40   
..       ...        ...   ...                ...        ...            ...   
71     13.86       1.51  2.67               25.0       86.0           2.95   
106    12.25       1.73  2.12               19.0       80.0           1.65   
14     14.38       1.87  2.38               12.0      102.0           3.30   
92     12.69       1.53  2.26               20.7       80.0           1.38   
102    12.34       2.45  2.46               21.0       98.0           2.56   

     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \
158        1.31                  0.53             2.70            13.00  0.57   
137        0.60                  0.63             1.10             5.00  0.82   
98         3.75                  0.24             1.95             4.50  1.04   
159        1.10                  0.52             2.29            11.75  0.57   
38         2.64                  0.28             1.37             3.70  1.18   
..          ...                   ...              ...              ...   ...   
71         2.86                  0.21             1.87             3.38  1.36   
106        2.03                  0.37             1.63             3.40  1.00   
14         3.64                  0.29             2.96             7.50  1.20   
92         1.46                  0.58             1.62             3.05  0.96   
102        2.11                  0.34             1.31             2.80  0.80   

     0D280_0D315_of_diluted_wines  Proline  class  
158                          1.96    660.0    3.0  
137                          1.69    515.0    3.0  
98                           2.77    660.0    2.0  
159                          1.78    620.0    3.0  
38                           2.69   1020.0    1.0  
..                            ...      ...    ...  
71                           3.16    410.0    2.0  
106                          3.17    510.0    2.0  
14                           3.00   1547.0    1.0  
92                           2.06    495.0    2.0  
102                          3.38    438.0    2.0  

[142 rows x 14 columns]
</pre></div>
</div>
</div>
</div>
<p>Hasil diatas total data Train yakni 142 record.</p>
</section>
<section id="data-test">
<h3>Data Test<a class="headerlink" href="#data-test" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">test</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;Wine_test.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Testing dataset (jumlah data: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="p">)</span><span class="si">}</span><span class="s2">):&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Testing dataset (jumlah data: 36):
     Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \
19     13.64       3.10  2.56               15.2      116.0           2.70   
45     14.21       4.04  2.44               18.9      111.0           2.85   
140    12.93       2.81  2.70               21.0       96.0           1.54   
30     13.73       1.50  2.70               22.5      101.0           3.00   
67     12.37       1.17  1.92               19.6       78.0           2.11   
16     14.30       1.92  2.72               20.0      120.0           2.80   
119    12.00       3.43  2.00               19.0       87.0           2.00   
174    13.40       3.91  2.48               23.0      102.0           1.80   
109    11.61       1.35  2.70               20.0       94.0           2.74   
141    13.36       2.56  2.35               20.0       89.0           1.40   
24     13.50       1.81  2.61               20.0       96.0           2.53   
150    13.50       3.12  2.62               24.0      123.0           1.40   
41     13.41       3.84  2.12               18.8       90.0           2.45   
118    12.77       3.43  1.98               16.0       80.0           1.63   
15     13.63       1.81  2.70               17.2      112.0           2.85   
111    12.52       2.43  2.17               21.0       88.0           2.55   
113    11.41       0.74  2.50               21.0       88.0           2.48   
82     12.08       1.13  2.51               24.0       78.0           2.00   
9      13.86       1.35  2.27               16.0       98.0           2.98   
114    12.08       1.39  2.50               22.5       84.0           2.56   
18     14.19       1.59  2.48               16.5      108.0           3.30   
66     13.11       1.01  1.70               15.0       78.0           2.98   
60     12.33       1.10  2.28               16.0      101.0           2.05   
169    13.40       4.60  2.86               25.0      112.0           1.98   
171    12.77       2.39  2.28               19.5       86.0           1.39   
164    13.78       2.76  2.30               22.0       90.0           1.35   
117    12.42       1.61  2.19               22.5      108.0           2.00   
65     12.37       1.21  2.56               18.1       98.0           2.42   
90     12.08       1.83  2.32               18.5       81.0           1.60   
55     13.56       1.73  2.46               20.5      116.0           2.96   
29     14.02       1.68  2.21               16.0       96.0           2.65   
128    12.37       1.63  2.30               24.5       88.0           2.22   
145    13.16       3.57  2.15               21.0      102.0           1.50   
31     13.58       1.66  2.36               19.1      106.0           2.86   
12     13.75       1.73  2.41               16.0       89.0           2.60   
42     13.88       1.89  2.59               15.0      101.0           3.25   

     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \
19         3.03                  0.17             1.66         5.100000  0.96   
45         2.65                  0.30             1.25         5.240000  0.87   
140        0.50                  0.53             0.75         4.600000  0.77   
30         3.25                  0.29             2.38         5.700000  1.19   
67         2.00                  0.27             1.04         4.680000  1.12   
16         3.14                  0.33             1.97         6.200000  1.07   
119        1.64                  0.37             1.87         1.280000  0.93   
174        0.75                  0.43             1.41         7.300000  0.70   
109        2.92                  0.29             2.49         2.650000  0.96   
141        0.50                  0.37             0.64         5.600000  0.70   
24         2.61                  0.28             1.66         3.520000  1.12   
150        1.57                  0.22             1.25         8.600000  0.59   
41         2.68                  0.27             1.48         4.280000  0.91   
118        1.25                  0.43             0.83         3.400000  0.70   
15         2.91                  0.30             1.46         7.300000  1.28   
111        2.27                  0.26             1.22         2.000000  0.90   
113        2.01                  0.42             1.44         3.080000  1.10   
82         1.58                  0.40             1.40         2.200000  1.31   
9          3.15                  0.22             1.85         7.220000  1.01   
114        2.29                  0.43             1.04         2.900000  0.93   
18         3.93                  0.32             1.86         8.700000  1.23   
66         3.18                  0.26             2.28         5.300000  1.12   
60         1.09                  0.63             0.41         3.270000  1.25   
169        0.96                  0.27             1.11         8.500000  0.67   
171        0.51                  0.48             0.64         9.899999  0.57   
164        0.68                  0.41             1.03         9.580000  0.70   
117        2.09                  0.34             1.61         2.060000  1.06   
65         2.65                  0.37             2.08         4.600000  1.19   
90         1.50                  0.52             1.64         2.400000  1.08   
55         2.78                  0.20             2.45         6.250000  0.98   
29         2.33                  0.26             1.98         4.700000  1.04   
128        2.45                  0.40             1.90         2.120000  0.89   
145        0.55                  0.43             1.30         4.000000  0.60   
31         3.19                  0.22             1.95         6.900000  1.09   
12         2.76                  0.29             1.81         5.600000  1.15   
42         3.56                  0.17             1.70         5.430000  0.88   

     0D280_0D315_of_diluted_wines  Proline  class  
19                           3.36    845.0    1.0  
45                           3.33   1080.0    1.0  
140                          2.31    600.0    3.0  
30                           2.71   1285.0    1.0  
67                           3.48    510.0    2.0  
16                           2.65   1280.0    1.0  
119                          3.05    564.0    2.0  
174                          1.56    750.0    3.0  
109                          3.26    680.0    2.0  
141                          2.47    780.0    3.0  
24                           3.82    845.0    1.0  
150                          1.30    500.0    3.0  
41                           3.00   1035.0    1.0  
118                          2.12    372.0    2.0  
15                           2.88   1310.0    1.0  
111                          2.78    325.0    2.0  
113                          2.31    434.0    2.0  
82                           2.72    630.0    2.0  
9                            3.55   1045.0    1.0  
114                          3.19    385.0    2.0  
18                           2.82   1680.0    1.0  
66                           3.18    502.0    2.0  
60                           1.67    680.0    2.0  
169                          1.92    630.0    3.0  
171                          1.63    470.0    3.0  
164                          1.68    615.0    3.0  
117                          2.96    345.0    2.0  
65                           2.30    678.0    2.0  
90                           2.27    480.0    2.0  
55                           3.03   1120.0    1.0  
29                           3.59   1035.0    1.0  
128                          2.78    342.0    2.0  
145                          1.68    830.0    3.0  
31                           2.88   1515.0    1.0  
12                           2.90   1320.0    1.0  
42                           3.56   1095.0    1.0  
</pre></div>
</div>
</div>
</div>
<p>Hasil diatas total data Test yakni 36 record.</p>
<p>Setelah Membagi Data Train dan data testnya selanjutnya kita bisa langsung ke implementasi prediksi model dengan bantuan Sklearn Naive Bayes.</p>
</section>
</section>
<section id="melakukan-prediksi-dengan-bantuan-sklearn-naive-bayes">
<h2>Melakukan Prediksi dengan bantuan Sklearn Naive Bayes<a class="headerlink" href="#melakukan-prediksi-dengan-bantuan-sklearn-naive-bayes" title="Link to this heading">#</a></h2>
<p>Berikutnya kita akan membuktikan apakah prediksi model melalui bantuan sklearn. Dan berikut untuk Akurasi data nya.</p>
<section id="hasil-akurasi-predict-data">
<h3>Hasil Akurasi &amp; Predict Data<a class="headerlink" href="#hasil-akurasi-predict-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Impor library yang diperlukan</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="c1"># Memuat dataset dari file CSV</span>
<span class="n">wine_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;wine.csv&#39;</span><span class="p">)</span>

<span class="c1"># Memisahkan fitur (X) dan target (y) dari dataset</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>  <span class="c1"># Anggap &#39;class&#39; adalah kolom target</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine_data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>

<span class="c1"># Memisahkan dataset menjadi data latih dan data uji</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>

<span class="c1"># Menggabungkan fitur dan label data latih ke dalam DataFrame untuk disimpan</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Menggabungkan fitur dan label data uji ke dalam DataFrame untuk disimpan</span>
<span class="n">test_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Menyimpan data latih dan data uji ke dalam file CSV</span>
<span class="n">train_data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;Wine_Train.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">test_data</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;Wine_Test.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># Konfirmasi penyimpanan</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data train dan test berhasil disimpan.&quot;</span><span class="p">)</span>

<span class="c1"># Membangun model Naive Bayes Gaussian</span>
<span class="n">gnb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>

<span class="c1"># Melatih model menggunakan data latih</span>
<span class="n">gnb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Memprediksi label untuk data uji</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">gnb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="c1"># Evaluasi performa model</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Akurasi: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s1">.2f</span><span class="si">}</span><span class="s1">%&#39;</span><span class="p">)</span>

<span class="c1"># Memprediksi kelas untuk data baru</span>
<span class="n">new_data_point</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">13.0</span><span class="p">,</span> <span class="mf">2.14</span><span class="p">,</span> <span class="mf">2.67</span><span class="p">,</span> <span class="mf">15.6</span><span class="p">,</span> <span class="mf">98.0</span><span class="p">,</span> <span class="mf">2.10</span><span class="p">,</span> <span class="mf">1.28</span><span class="p">,</span> <span class="mf">0.27</span><span class="p">,</span> <span class="mf">1.04</span><span class="p">,</span> <span class="mf">4.38</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">,</span> <span class="mf">3.40</span><span class="p">,</span> <span class="mf">1050.0</span><span class="p">]]</span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">gnb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_data_point</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Hasil Class Varietas yang diprediksi untuk data baru:&#39;</span><span class="p">,</span> <span class="n">predicted_class</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data train dan test berhasil disimpan.
Akurasi: 100.00%
Hasil Class Varietas yang diprediksi untuk data baru: [2]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Adi Sahrul R\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but GaussianNB was fitted with feature names
  warnings.warn(
</pre></div>
</div>
</div>
</div>
<p>Hasil diatas menyentuh angka  80 % - 100%. Rentang ini sering dianggap sebagai akurasi yang Sangat baik. Model dengan akurasi di kisaran ini biasanya dianggap Sangat efektif untuk banyak aplikasi. Hasil diatas prediksi dengan perhitunganya yakni Class Kecimen dengan inputan dari data x test yakni [13.0, 2.14, 2.67, 15.6, 98.0, 2.10, 1.28, 0.27, 1.04, 4.38, 1.05, 3.40, 1050.0] Hasil Prediksinya Class 2.</p>
</section>
</section>
<section id="kesimpulan-hasil-analisis-klasifikasi">
<h2>Kesimpulan Hasil Analisis Klasifikasi  :<a class="headerlink" href="#kesimpulan-hasil-analisis-klasifikasi" title="Link to this heading">#</a></h2>
<p>Dapat kita simpulkan dengan metode klasifikasi Naive Bayes ini dengan nilai prediksi 100%. Bisa dikatakan sangat Sempurna untuk menentukan atau sortir Kategori Class Wine dari perhitungan dari masing-masing fiturnya. Dengan hasil analisis dengan Metode Klasifikasi ini dapat membantu
sistem penyortiran class Wine untuk meningkatkan
efisiensi di industri maupun pabrik.</p>
<section id="pertemuan-baru-dengan-pengembangan-baru-model-baru">
<h3>Pertemuan Baru dengan Pengembangan Baru Model Baru<a class="headerlink" href="#pertemuan-baru-dengan-pengembangan-baru-model-baru" title="Link to this heading">#</a></h3>
</section>
</section>
<section id="ensemble-learning">
<h2>Ensemble Learning<a class="headerlink" href="#ensemble-learning" title="Link to this heading">#</a></h2>
<img src="barugambar/image-20240612-235103.png" width="50%" align="center" /><p>Metode ensemble adalah teknik yang menggabungkan beberapa classifier individu untuk membentuk classifier baru, dengan tujuan untuk mencapai hasil yang lebih akurat. Metode ini telah banyak digunakan dalam berbagai penelitian karena terbukti mampu meningkatkan akurasi. Dalam metode ensemble, beberapa classifier individu digabungkan untuk menggabungkan kelebihan masing-masing classifier sehingga kinerja keseluruhan dalam menyelesaikan tugas menjadi lebih baik. Contoh umum dari metode ensemble termasuk bagging, boosting, dan stacking. Namun, dalam kesempatan ini, kami hanya akan menggunakan bagging dan stacking untuk meningkatkan model.</p>
</section>
<section id="stacking-classifier-meta-classifier">
<h2>2. Stacking Classifier (Meta Classifier)<a class="headerlink" href="#stacking-classifier-meta-classifier" title="Link to this heading">#</a></h2>
<p>(Stacked Generalization) adalah teknik pembelajaran ensemble yang bertujuan untuk menggabungkan beberapa model untuk meningkatkan kinerja prediktif. Ini melibatkan langkah-langkah berikut:</p>
<ol class="arabic simple">
<li><p>Model Dasar : Melatih beberapa model pada kumpulan data yang sama.</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p>Meta-Model : Melatih model baru untuk menggabungkan prediksi model dasar. Menggunakan prediksi model dasar sebagai fitur masukan untuk model meta.</p></li>
</ol>
<p>Keuntungan / Kelebihan nya :</p>
<ol class="arabic simple">
<li><p>Memanfaatkan Keanekaragaman Model : Dengan menggabungkan berbagai jenis model, penumpukan dapat menangkap berbagai pola dalam data.</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p>Meningkatkan Performa : Model meta mempelajari cara terbaik untuk menggabungkan prediksi dari model dasar, yang sering kali menghasilkan peningkatan performa dibandingkan model individual.</p></li>
</ol>
<img src="barugambar/image-20240612-184821.png" width="75%" align="" /><p>Langkah - langkah proses Gambar Stacking Diatas :</p>
<ol class="arabic simple">
<li><p>Persiapan Data: Pisahkan dataset menjadi fitur (X) dan label (y), kemudian bagi dataset menjadi set pelatihan dan pengujian.</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p>Latih Model Dasar (Base Models): Latih beberapa model dasar menggunakan data pelatihan.</p></li>
</ol>
<ol class="arabic simple" start="3">
<li><p>Kumpulkan Prediksi dari Model Dasar: Gunakan model dasar yang telah dilatih untuk membuat prediksi pada set pelatihan dan pengujian.</p></li>
</ol>
<ol class="arabic simple" start="4">
<li><p>Latih Meta-Classifier:Gunakan prediksi dari model dasar sebagai fitur baru untuk melatih meta-classifier.</p></li>
</ol>
<ol class="arabic simple" start="5">
<li><p>Evaluasi dan Prediksi: Gunakan meta-classifier untuk membuat prediksi akhir dan evaluasi kinerja model.</p></li>
</ol>
<p>Setelah kita memahami dengan baik Stacking classifier dan langkah-langkahnya berikut kita implementasikan.</p>
<section id="a-meta-predict-classifier-model-naive-bayes-manual">
<h3>A. Meta Predict Classifier Model Naive Bayes Manual<a class="headerlink" href="#a-meta-predict-classifier-model-naive-bayes-manual" title="Link to this heading">#</a></h3>
</section>
<section id="model-p1">
<h3>Model P1<a class="headerlink" href="#model-p1" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Install paket yang diperlukan</span>
<span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>ucimlrepo

<span class="c1"># Import library yang diperlukan</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># Memuat dataset dari file CSV</span>
<span class="n">wine_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;wine.csv&#39;</span><span class="p">)</span>

<span class="c1"># Memisahkan fitur dan target dari dataset</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>  <span class="c1"># Mengasumsikan &#39;class&#39; sebagai kolom target</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine_data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>

<span class="c1"># Encode labels jika diperlukan</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Bagi dataset menjadi data latih dan data uji</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Inisialisasi classifier KNN dengan k=3</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Latih model pada data latih</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluasi model pada data latih</span>
<span class="n">XTrain1</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">accuracy_train</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">XTrain1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi pada data train: </span><span class="si">{</span><span class="n">accuracy_train</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Evaluasi model pada data uji</span>
<span class="n">XTest1</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">accuracy_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">XTest1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi pada data test: </span><span class="si">{</span><span class="n">accuracy_test</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Prediksi untuk instance baru</span>
<span class="n">new_data</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">13.0</span><span class="p">,</span> <span class="mf">2.14</span><span class="p">,</span> <span class="mf">2.67</span><span class="p">,</span> <span class="mf">15.6</span><span class="p">,</span> <span class="mf">98.0</span><span class="p">,</span> <span class="mf">2.10</span><span class="p">,</span> <span class="mf">1.28</span><span class="p">,</span> <span class="mf">0.27</span><span class="p">,</span> <span class="mf">1.04</span><span class="p">,</span> <span class="mf">4.38</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">,</span> <span class="mf">3.40</span><span class="p">,</span> <span class="mf">1050.0</span><span class="p">]]</span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediksi Class Varietas untuk data inputan baru: </span><span class="si">{</span><span class="n">predicted_class</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: ucimlrepo in c:\users\adi sahrul r\appdata\local\programs\python\python312\lib\site-packages (0.0.6)
Akurasi pada data train: 0.89
Akurasi pada data test: 0.78
Prediksi Class Varietas untuk data inputan baru: [1]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>DEPRECATION: Loading egg at c:\users\adi sahrul r\appdata\local\programs\python\python312\lib\site-packages\nmslib-2.1.2-py3.12-win-amd64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330
C:\Users\Adi Sahrul R\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
  warnings.warn(
</pre></div>
</div>
</div>
</div>
</section>
<section id="model-p2">
<h3>Model P2<a class="headerlink" href="#model-p2" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import library yang diperlukan</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1"># Memuat dataset dari file CSV</span>
<span class="n">wine_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;wine.csv&#39;</span><span class="p">)</span>

<span class="c1"># Memisahkan fitur dan target dari dataset</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>  <span class="c1"># Mengasumsikan &#39;class&#39; sebagai kolom target</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine_data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>

<span class="c1"># Encode labels jika diperlukan</span>
<span class="n">label_encoder</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

<span class="c1"># Bagi dataset menjadi data latih dan data uji</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Inisialisasi classifier KNN dengan k=5</span>
<span class="n">classifier</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>

<span class="c1"># Latih model pada data latih</span>
<span class="n">classifier</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluasi model pada data latih</span>
<span class="n">XTrain2</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">accuracy_train</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">XTrain2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi pada data train: </span><span class="si">{</span><span class="n">accuracy_train</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Evaluasi model pada data uji</span>
<span class="n">XTest2</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">accuracy_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">XTest2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi pada data test: </span><span class="si">{</span><span class="n">accuracy_test</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Prediksi untuk instance baru</span>
<span class="n">new_data</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">13.0</span><span class="p">,</span> <span class="mf">2.14</span><span class="p">,</span> <span class="mf">2.67</span><span class="p">,</span> <span class="mf">15.6</span><span class="p">,</span> <span class="mf">98.0</span><span class="p">,</span> <span class="mf">2.10</span><span class="p">,</span> <span class="mf">1.28</span><span class="p">,</span> <span class="mf">0.27</span><span class="p">,</span> <span class="mf">1.04</span><span class="p">,</span> <span class="mf">4.38</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">,</span> <span class="mf">3.40</span><span class="p">,</span> <span class="mf">1050.0</span><span class="p">]]</span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">classifier</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">new_data</span><span class="p">)</span>
<span class="n">predicted_class</span> <span class="o">=</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">predicted_class</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediksi Class Varietas untuk data inputan baru: </span><span class="si">{</span><span class="n">predicted_class</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Akurasi pada data train: 0.79
Akurasi pada data test: 0.81
Prediksi Class Varietas untuk data inputan baru: [1]
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>C:\Users\Adi Sahrul R\AppData\Local\Programs\Python\Python312\Lib\site-packages\sklearn\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names
  warnings.warn(
</pre></div>
</div>
</div>
</div>
</section>
<section id="menggabungkan-hasil-prediksi-2-model">
<h3>Menggabungkan hasil prediksi 2 model<a class="headerlink" href="#menggabungkan-hasil-prediksi-2-model" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Buat DataFrame gabungan untuk data pengujian</span>
<span class="n">combined_train_df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;P1&#39;</span><span class="p">:</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">XTrain1</span><span class="p">),</span>
    <span class="s1">&#39;P2&#39;</span><span class="p">:</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">XTrain2</span><span class="p">),</span>
    <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="p">})</span>

<span class="n">combined_train_df1</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;combine_train1.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Buat DataFrame gabungan untuk data pengujian</span>
<span class="n">combined_test_df1</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s1">&#39;P1&#39;</span><span class="p">:</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">XTest1</span><span class="p">),</span>
    <span class="s1">&#39;P2&#39;</span><span class="p">:</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">XTest2</span><span class="p">),</span>
    <span class="s1">&#39;Y&#39;</span><span class="p">:</span> <span class="n">label_encoder</span><span class="o">.</span><span class="n">inverse_transform</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="p">})</span>

<span class="n">combined_test_df1</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;combine_test1.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Hasil Train</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;combine_train1.csv&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>P1</th>
      <th>P2</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>137</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>138</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>139</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>140</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>141</th>
      <td>3</td>
      <td>3</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
<p>142 rows × 3 columns</p>
</div></div></div>
</div>
<p>Hasil Test</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;combine_test1.csv&#39;</span><span class="p">)</span>
<span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>P1</th>
      <th>P2</th>
      <th>Y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>6</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>2</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>8</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>9</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>10</th>
      <td>1</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>11</th>
      <td>2</td>
      <td>2</td>
      <td>3</td>
    </tr>
    <tr>
      <th>12</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>13</th>
      <td>3</td>
      <td>3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>14</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
    </tr>
    <tr>
      <th>15</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>16</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>17</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>18</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>19</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>20</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>21</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22</th>
      <td>3</td>
      <td>3</td>
      <td>1</td>
    </tr>
    <tr>
      <th>23</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>24</th>
      <td>1</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>25</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>26</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>27</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>28</th>
      <td>3</td>
      <td>3</td>
      <td>2</td>
    </tr>
    <tr>
      <th>29</th>
      <td>3</td>
      <td>3</td>
      <td>3</td>
    </tr>
    <tr>
      <th>30</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>31</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>32</th>
      <td>2</td>
      <td>2</td>
      <td>2</td>
    </tr>
    <tr>
      <th>33</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>34</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>35</th>
      <td>1</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
</section>
<section id="implementasi-stacking-dengan-scikit-learn">
<h3>Implementasi stacking dengan scikit-learn<a class="headerlink" href="#implementasi-stacking-dengan-scikit-learn" title="Link to this heading">#</a></h3>
<p>Setelah memahami proses stacking classifier untuk meningkatkan model secara manual, langkah berikutnya adalah memanfaatkan library untuk melatih model dasar. Melatih model dasar satu per satu bukanlah solusi praktis, terutama karena kami berencana menggunakan 20 model KNN dengan nilai K yang berbeda. Oleh karena itu, kami akan menggunakan bantuan library untuk mempercepat dan mempermudah proses pelatihan ini. Prediksi dari 20 model tersebut kemudian akan digabungkan dan dimasukkan ke dalam model Gaussian Naive Bayes untuk tahap akhir prediksi. Dengan pendekatan ini, kami berharap dapat mengoptimalkan kinerja model secara keseluruhan.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">StackingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="c1"># Load dataset from CSV</span>
<span class="n">wine_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;wine.csv&#39;</span><span class="p">)</span>

<span class="c1"># Separate features and target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">wine_data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span><span class="o">.</span><span class="n">values</span>  <span class="c1"># Assuming &#39;class&#39; is the target column</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">wine_data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>

<span class="c1"># Split data into training and testing sets</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Create list of estimators for StackingClassifier</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="p">[(</span><span class="s1">&#39;knn&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span> <span class="o">//</span> <span class="mi">3</span><span class="p">),</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">i</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">63</span><span class="p">,</span> <span class="mi">3</span><span class="p">)]</span>

<span class="c1"># Initialize StackingClassifier with GaussianNB as final estimator</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">StackingClassifier</span><span class="p">(</span>
    <span class="n">estimators</span><span class="o">=</span><span class="n">estimators</span><span class="p">,</span> <span class="n">final_estimator</span><span class="o">=</span><span class="n">GaussianNB</span><span class="p">()</span>
<span class="p">)</span>

<span class="c1"># Train StackingClassifier</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># Evaluate accuracy for each KNN model and store the results</span>
<span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="n">estimators</span><span class="p">:</span>
    <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Accuracy of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy</span><span class="p">)</span>

<span class="c1"># Display accuracy of each KNN model</span>
<span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">accuracy</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">name</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">estimators</span><span class="p">],</span> <span class="n">accuracies</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Evaluate predictions for new data point by each KNN model</span>
<span class="c1"># Example new data point with 13 features</span>
<span class="n">X_new</span> <span class="o">=</span> <span class="p">[[</span><span class="mf">13.0</span><span class="p">,</span> <span class="mf">2.14</span><span class="p">,</span> <span class="mf">2.67</span><span class="p">,</span> <span class="mf">15.6</span><span class="p">,</span> <span class="mf">98.0</span><span class="p">,</span> <span class="mf">2.10</span><span class="p">,</span> <span class="mf">1.28</span><span class="p">,</span> <span class="mf">0.27</span><span class="p">,</span> <span class="mf">1.04</span><span class="p">,</span> <span class="mf">4.38</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">,</span> <span class="mf">3.40</span><span class="p">,</span> <span class="mf">1050.0</span><span class="p">]]</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">estimator</span> <span class="ow">in</span> <span class="n">estimators</span><span class="p">:</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">predictions</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediction of </span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">pred</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Counting predictions for each class</span>
<span class="n">unique_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">counts</span> <span class="o">=</span> <span class="p">{</span><span class="bp">cls</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">predictions</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> <span class="k">if</span> <span class="n">pred</span> <span class="o">==</span> <span class="bp">cls</span><span class="p">)</span> <span class="k">for</span> <span class="bp">cls</span> <span class="ow">in</span> <span class="n">unique_classes</span><span class="p">}</span>

<span class="c1"># Display number of predictions for each class</span>
<span class="k">for</span> <span class="bp">cls</span><span class="p">,</span> <span class="n">count</span> <span class="ow">in</span> <span class="n">counts</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Class </span><span class="si">{</span><span class="bp">cls</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">count</span><span class="si">}</span><span class="s2"> predictions&quot;</span><span class="p">)</span>

<span class="c1"># Predict for new data using StackingClassifier</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Prediction for X_new: </span><span class="si">{</span><span class="n">prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Evaluate overall performance of the stacking classifier</span>
<span class="n">avg_acc</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Overall Stacking Classifier Performance:&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Accuracy: </span><span class="si">{</span><span class="n">avg_acc</span><span class="si">:</span><span class="s1">.4f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Obtain predictions from the model</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy of knn1: 0.7778
Accuracy of knn2: 0.7500
Accuracy of knn3: 0.7500
Accuracy of knn4: 0.6944
Accuracy of knn5: 0.7222
Accuracy of knn6: 0.7500
Accuracy of knn7: 0.7500
Accuracy of knn8: 0.7500
Accuracy of knn9: 0.7500
Accuracy of knn10: 0.7500
Accuracy of knn11: 0.7500
Accuracy of knn12: 0.7500
Accuracy of knn13: 0.7500
Accuracy of knn14: 0.7500
Accuracy of knn15: 0.7500
Accuracy of knn16: 0.7500
Accuracy of knn17: 0.7500
Accuracy of knn18: 0.7500
Accuracy of knn19: 0.7500
Accuracy of knn20: 0.7500
knn1: 0.7778
knn2: 0.7500
knn3: 0.7500
knn4: 0.6944
knn5: 0.7222
knn6: 0.7500
knn7: 0.7500
knn8: 0.7500
knn9: 0.7500
knn10: 0.7500
knn11: 0.7500
knn12: 0.7500
knn13: 0.7500
knn14: 0.7500
knn15: 0.7500
knn16: 0.7500
knn17: 0.7500
knn18: 0.7500
knn19: 0.7500
knn20: 0.7500
Prediction of knn1: 1
Prediction of knn2: 1
Prediction of knn3: 1
Prediction of knn4: 1
Prediction of knn5: 1
Prediction of knn6: 1
Prediction of knn7: 1
Prediction of knn8: 1
Prediction of knn9: 1
Prediction of knn10: 1
Prediction of knn11: 1
Prediction of knn12: 1
Prediction of knn13: 1
Prediction of knn14: 1
Prediction of knn15: 1
Prediction of knn16: 1
Prediction of knn17: 1
Prediction of knn18: 1
Prediction of knn19: 1
Prediction of knn20: 1
Class 1: 20 predictions
Class 2: 0 predictions
Class 3: 0 predictions

Prediction for X_new: 1

Overall Stacking Classifier Performance:
Accuracy: 0.7778
              precision    recall  f1-score   support

           1       1.00      0.93      0.96        14
           2       0.85      0.69      0.76        16
           3       0.40      0.67      0.50         6

    accuracy                           0.78        36
   macro avg       0.75      0.76      0.74        36
weighted avg       0.83      0.78      0.79        36
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="bagging-bootstrap-aggregating">
<h2>3. Bagging (Bootstrap Aggregating)<a class="headerlink" href="#bagging-bootstrap-aggregating" title="Link to this heading">#</a></h2>
<img src="barugambar/image-20240613-000652.png" width="75%" align="" /><p>Bagging, kependekan dari agregasi bootstrap, terutama diterapkan dalam klasifikasi dan regresi . Hal ini meningkatkan akurasi model melalui pohon keputusan, sehingga mengurangi varians secara signifikan. Pengurangan varians meningkatkan akurasi, menghilangkan overfitting, yang merupakan tantangan bagi banyak model prediktif. Secara umum untuk masalah regresi. Ini melibatkan pengambilan rata-rata prediksi. Rata-rata yang dihasilkan digunakan sebagai prediksi keseluruhan untuk model gabungan.</p>
<p>Proses Klasifikasi Bagging melibatkan langkah-langkah berikut:</p>
<ol class="arabic simple">
<li><p>Kita mengambil dataset pelatihan awal yang dimiliki.</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p>Lalu kita membuat sejumlah m subset data dari set pelatihan. Kami mengambil subset N titik sampel dari dataset awal untuk setiap subset. Setiap subset diambil dengan penggantian. Artinya, titik data tertentu dapat diambil sampelnya lebih dari satu kali.</p></li>
</ol>
<ol class="arabic simple" start="3">
<li><p>Lalu model yang sama (classifier) diterapkan pada setiap set data pelatihan ini dan menghasilkan prediksi masing-masing.</p></li>
</ol>
<ol class="arabic simple" start="4">
<li><p>Setiap model membuat prediksi.</p></li>
</ol>
<ol class="arabic simple" start="5">
<li><p>Terakhir tingga menggabungkan prediksi menjadi satu prediksi. Untuk ini, gunakan max voting atau averaging.</p></li>
</ol>
<p>Setelah memahami maka pada percobaan kali ini bagging kami menggunakan 20 gaussian naive bayes yang menerima subset berbeda satu sama lain. Berikut Ini Implementasinya.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1"># Memuat dataset dari file CSV</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;wine.csv&#39;</span><span class="p">)</span>

<span class="c1"># Menghapus kolom &#39;Unnamed: 0&#39; jika ada</span>
<span class="k">if</span> <span class="s1">&#39;Unnamed: 0&#39;</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
    <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Unnamed: 0&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Memisahkan atribut dan label</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">])</span>  <span class="c1"># Atribut</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;class&#39;</span><span class="p">]</span>  <span class="c1"># Label</span>

<span class="c1"># Pembagian dataset menjadi data latih dan data uji dengan rasio 80:20</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Parameter untuk teknik Bagging</span>
<span class="n">n_estimators</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">n_samples</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span> <span class="o">/</span> <span class="n">n_estimators</span><span class="p">)</span>

<span class="c1"># Inisialisasi list untuk menyimpan model dan akurasi</span>
<span class="n">estimators</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">accuracies</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">pred</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Data baru yang akan diprediksi</span>
<span class="n">X_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([[</span><span class="mf">13.0</span><span class="p">,</span> <span class="mf">2.14</span><span class="p">,</span> <span class="mf">2.67</span><span class="p">,</span> <span class="mf">15.6</span><span class="p">,</span> <span class="mf">98.0</span><span class="p">,</span> <span class="mf">2.10</span><span class="p">,</span> <span class="mf">1.28</span><span class="p">,</span> <span class="mf">0.27</span><span class="p">,</span> <span class="mf">1.04</span><span class="p">,</span> <span class="mf">4.38</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">,</span> <span class="mf">3.40</span><span class="p">,</span> <span class="mf">1050.0</span><span class="p">]],</span>
                     <span class="n">columns</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data baru yang akan diprediksi:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>
<span class="nb">print</span><span class="p">()</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Membuat model Gaussian Naive Bayes untuk setiap subset</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_estimators</span><span class="p">):</span>
    <span class="c1"># Membuat sampel bootstrap</span>
    <span class="n">bootstrap_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">n_samples</span><span class="p">)</span>
    <span class="n">X_train_bootstrap</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">bootstrap_indices</span><span class="p">]</span>
    <span class="n">y_train_bootstrap</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">bootstrap_indices</span><span class="p">]</span>
    
    <span class="c1"># Melatih model</span>
    <span class="n">gnb_model</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
    <span class="n">gnb_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_bootstrap</span><span class="p">,</span> <span class="n">y_train_bootstrap</span><span class="p">)</span>
    <span class="n">estimators</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">gnb_model</span><span class="p">)</span>
    
    <span class="c1"># Evaluasi model    </span>
    <span class="n">prediksi</span> <span class="o">=</span> <span class="n">gnb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_new</span><span class="p">)</span>
    <span class="n">pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">prediksi</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>  <span class="c1"># Menyimpan prediksi dalam list pred</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">gnb_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">akurasi</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">accuracies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">akurasi</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi Estimator </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> : </span><span class="si">{</span><span class="n">akurasi</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediksi Estimator </span><span class="si">{</span><span class="n">i</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> : </span><span class="si">{</span><span class="n">prediksi</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">()</span>

<span class="c1"># Majority vote untuk prediksi data baru</span>
<span class="n">prediksi_majority_vote</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span><span class="o">.</span><span class="n">argmax</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Prediksi mayoritas untuk data baru: </span><span class="si">{</span><span class="n">prediksi_majority_vote</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menghitung jumlah prediksi untuk setiap kelas</span>
<span class="n">class_counts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">minlength</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)))</span>
<span class="k">for</span> <span class="n">kelas</span><span class="p">,</span> <span class="n">jumlah</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">class_counts</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Jumlah prediksi untuk kelas </span><span class="si">{</span><span class="n">kelas</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">jumlah</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Menghitung rata-rata akurasi dari semua estimators</span>
<span class="n">akurasi_rata_rata</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">accuracies</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Akurasi rata-rata dari semua estimators: </span><span class="si">{</span><span class="n">akurasi_rata_rata</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Plot akurasi untuk masing-masing estimator</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span> <span class="n">accuracies</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;skyblue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Estimator&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Akurasi&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Akurasi dari Setiap Estimator Gaussian Naive Bayes&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_estimators</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Plot jumlah prediksi untuk setiap kelas pada data baru</span>
<span class="n">label_kelas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">nilai_kelas</span> <span class="o">=</span> <span class="p">[</span><span class="n">class_counts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">label_kelas</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">label_kelas</span><span class="p">,</span> <span class="n">nilai_kelas</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;lightgreen&#39;</span><span class="p">,</span> <span class="s1">&#39;salmon&#39;</span><span class="p">,</span> <span class="s1">&#39;skyblue&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Kelas&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Jumlah Prediksi&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Jumlah Prediksi untuk Setiap Kelas oleh Estimators untuk Data Baru&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data baru yang akan diprediksi:
   Alcohol  Malicacid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \
0     13.0       2.14  2.67               15.6       98.0            2.1   

   Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \
0        1.28                  0.27             1.04             4.38  1.05   

   0D280_0D315_of_diluted_wines  Proline  
0                           3.4   1050.0  

Akurasi Estimator 1 : 0.3889
Prediksi Estimator 1 : 1

Akurasi Estimator 2 : 0.3889
Prediksi Estimator 2 : 1

Akurasi Estimator 3 : 0.5278
Prediksi Estimator 3 : 1

Akurasi Estimator 4 : 0.3889
Prediksi Estimator 4 : 1

Akurasi Estimator 5 : 0.6389
Prediksi Estimator 5 : 2

Akurasi Estimator 6 : 0.7222
Prediksi Estimator 6 : 2

Akurasi Estimator 7 : 0.4444
Prediksi Estimator 7 : 2

Akurasi Estimator 8 : 0.3889
Prediksi Estimator 8 : 1

Akurasi Estimator 9 : 0.6944
Prediksi Estimator 9 : 2

Akurasi Estimator 10 : 0.1667
Prediksi Estimator 10 : 3

Akurasi Estimator 11 : 0.5278
Prediksi Estimator 11 : 2

Akurasi Estimator 12 : 0.3889
Prediksi Estimator 12 : 3

Akurasi Estimator 13 : 0.4722
Prediksi Estimator 13 : 2

Akurasi Estimator 14 : 0.5556
Prediksi Estimator 14 : 1

Akurasi Estimator 15 : 0.3889
Prediksi Estimator 15 : 3

Akurasi Estimator 16 : 0.4722
Prediksi Estimator 16 : 2

Akurasi Estimator 17 : 0.7222
Prediksi Estimator 17 : 3

Akurasi Estimator 18 : 0.4167
Prediksi Estimator 18 : 1

Akurasi Estimator 19 : 0.4444
Prediksi Estimator 19 : 2

Akurasi Estimator 20 : 0.5556
Prediksi Estimator 20 : 1

Prediksi mayoritas untuk data baru: 1
Jumlah prediksi untuk kelas 0: 0
Jumlah prediksi untuk kelas 1: 8
Jumlah prediksi untuk kelas 2: 8
Jumlah prediksi untuk kelas 3: 4
Akurasi rata-rata dari semua estimators: 0.4847
</pre></div>
</div>
<img alt="_images/8d50fb9685d68ddaa3e91701165aa1daacb16629c6355a44e90cb37169415c96.png" src="_images/8d50fb9685d68ddaa3e91701165aa1daacb16629c6355a44e90cb37169415c96.png" />
<img alt="_images/d7c853c0c7d635d6e3e496b0a43089344a5da93f1d2fed7acf35b111731a0f32.png" src="_images/d7c853c0c7d635d6e3e496b0a43089344a5da93f1d2fed7acf35b111731a0f32.png" />
</div>
</div>
</section>
<section id="kesimpulan-hasil-model-yang-didapatkan">
<h2>Kesimpulan Hasil Model Yang Didapatkan<a class="headerlink" href="#kesimpulan-hasil-model-yang-didapatkan" title="Link to this heading">#</a></h2>
<p>Dari ketiga yang kami buat sebelumnya dapat dikatakan baik atau bagus, hal itu dapat dilihat dari akurasi yang didapat dari masing-masing model yang sudah kita buktikan dengan hasil rata-rata diatas 80 % yang artinya tergolong sangat baik sebagai berikut hasilnya.</p>
<ul class="simple">
<li><p>single model dengan GNB : mendapatkan akurasi 100% atau 1.0.</p></li>
</ul>
<ul class="simple">
<li><p>stacking dengan KNN (model dasar) dan GNB (model meta) : mendapatkan akurasi 77,78% atau 0.7778.</p></li>
</ul>
<ul class="simple">
<li><p>bagging dengan GNB : mendapatkan akurasi 48,47% atau 0.4847.</p></li>
</ul>
<p>dari ketiga model diatas dapat dilihat bahwa model terbaik adalah single model dengan GNB karena mendapatkan akurasi tertinggi dari ketiga model yang telah dibuat yakni 100% atau 1.0. Jadi langkah selanjutnya kita pakai model terbaik tersebut untuk implementasinya.</p>
</section>
<section id="deployment-implementasi-model">
<h2>Deployment Implementasi Model<a class="headerlink" href="#deployment-implementasi-model" title="Link to this heading">#</a></h2>
<p>Pada tahap ini kita akan membuat implementasi Model single model dengan GNB sebagai model untuk menentukan klasifikasi untuk menentukan Varietas Wine yang akan digunakan untuk mempermudah untuk penyortiran dalam Industri Pabrik sortir Varietas Class Wine supaya efektif dalam waktu dan tenaga kerja profesional manual yang susah dicari untuk penyortiran Varietas Wine.</p>
<p>Dalam Implementasi yang kita buat kita menggunakan Python Flask yang tentunya membutuhkan library flask untuk menjalankannya.</p>
</section>
<section id="implementasi-web">
<h2>Implementasi Web<a class="headerlink" href="#implementasi-web" title="Link to this heading">#</a></h2>
<p>Tahapan Implementasi Flask untuk Prediksi Class Varietas Wine</p>
<ol class="arabic simple">
<li><p>Mengimpor Library yang Diperlukan</p></li>
</ol>
<ol class="arabic simple" start="2">
<li><p>Inisialisasi Aplikasi Flask</p></li>
</ol>
<ol class="arabic simple" start="3">
<li><p>Memuat dan Melatih Model</p></li>
</ol>
<ol class="arabic simple" start="4">
<li><p>Mendefinisikan Rute Utama dan Logika Prediksi</p></li>
</ol>
<ol class="arabic simple" start="5">
<li><p>Menjalankan Aplikasi Flask</p></li>
</ol>
<p>Maka Otomatis Web Flask kita bisa digunakan jika kita sesuaikan tahapan dan code yang kita buat. berikut adalah link implementasi yang sudah kita upload di github berikut linknya : <a class="github reference external" href="https://github.com/AdiSahrulRamadhan/wine-classification-flask">AdiSahrulRamadhan/wine-classification-flask</a></p>
</section>
<section id="hasil-implementasi-web">
<h2>Hasil Implementasi Web<a class="headerlink" href="#hasil-implementasi-web" title="Link to this heading">#</a></h2>
<p>link menuju website yang sudah kami buat atau hosting : <a class="reference external" href="https://adisahrul123.pythonanywhere.com/">https://adisahrul123.pythonanywhere.com/</a></p>
<p>Berikut Kita Setalah Klik Link kita Langsung Tes untuk Prediksinya kita masukkan inputan data test [13.0, 2.14, 2.67, 15.6, 98.0, 2.10, 1.28, 0.27, 1.04, 4.38, 1.05, 3.40, 1050.0].</p>
<img src="barugambar/image-20240626-141326.png" width="" align="" /><p>Maka Berikut Hasilnya :</p>
<img src="barugambar/image-20240626-141503.png" width="" align="" /><p>Seperti Hasil Model Terbaik yang kita gunakan kedalam inplementasi sangat sesuai hasilnya yakni termasuk kategorikan predict class ke 2 maka Implementasi yang kita buat sudah berhasil dengan berjalan sesuai dengan model terbaik yang kita gunakan yakni single model dengan GNB : mendapatkan akurasi 100% atau 1.0.</p>
<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=bd7bfa42-6d65-487b-b353-2531ed4bd5d7' target="_blank">
<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>
Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a></section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">1. Analisis Penelitian dan Implementasi Sistem Klasifikasi Varietas Anggur(Wine)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tujuan-analisis-dan-implementasi-sistem-klasifikasi-varietas-anggur-untuk-industri-pabrik-wine">Tujuan Analisis dan Implementasi Sistem Klasifikasi Varietas Anggur untuk Industri Pabrik Wine</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#apa-itu-wine">Apa Itu Wine?</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#data-understanding-memahami-data-kismis">2. Data Understanding / Memahami data kismis</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pengumpulan-data">Pengumpulan Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mencari-datasets">Mencari Datasets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#integrasi-data">Integrasi Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#mengambil-dan-menampilkan-datasets">Mengambil dan Menampilkan Datasets</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memahami-data">Memahami Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explore-mengetahui-kualitas-datasets-wine-dan-memahami">Explore / Mengetahui Kualitas Datasets Wine dan memahami</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jumlah-data-fitur-dan-tipe-data">Jumlah Data Fitur dan Tipe Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jumlah-data-dari-datasets-wine">Jumlah Data Dari Datasets Wine</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#jumlah-class-pada-data-kategori-setiap-class">Jumlah Class pada data / Kategori setiap Class</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deskripsi-datasets">Deskripsi Datasets</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#identifikasi-kualitas-data">Identifikasi Kualitas Data</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-data-missing-values">1. Deteksi Data Missing Values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-data-outlier">2. Deteksi Data Outlier</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#deteksi-duplikasi-datasets">3. Deteksi Duplikasi Datasets</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing-data">3.Preprocessing Data</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#modelling">4. Modelling</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#pemilihan-model">Pemilihan Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gaussian-naive-bayes-classification">GAUSSIAN NAIVE BAYES CLASSIFICATION</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#membagi-data-train-data-test">Membagi Data Train &amp; Data Test</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-train">Data Train</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-test">Data Test</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#melakukan-prediksi-dengan-bantuan-sklearn-naive-bayes">Melakukan Prediksi dengan bantuan Sklearn Naive Bayes</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-akurasi-predict-data">Hasil Akurasi &amp; Predict Data</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-hasil-analisis-klasifikasi">Kesimpulan Hasil Analisis Klasifikasi  :</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pertemuan-baru-dengan-pengembangan-baru-model-baru">Pertemuan Baru dengan Pengembangan Baru Model Baru</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ensemble-learning">Ensemble Learning</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#stacking-classifier-meta-classifier">2. Stacking Classifier (Meta Classifier)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-meta-predict-classifier-model-naive-bayes-manual">A. Meta Predict Classifier Model Naive Bayes Manual</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-p1">Model P1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#model-p2">Model P2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#menggabungkan-hasil-prediksi-2-model">Menggabungkan hasil prediksi 2 model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-stacking-dengan-scikit-learn">Implementasi stacking dengan scikit-learn</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#bagging-bootstrap-aggregating">3. Bagging (Bootstrap Aggregating)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#kesimpulan-hasil-model-yang-didapatkan">Kesimpulan Hasil Model Yang Didapatkan</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#deployment-implementasi-model">Deployment Implementasi Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementasi-web">Implementasi Web</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hasil-implementasi-web">Hasil Implementasi Web</a></li>
</ul>
</li>
</ul>

</nav></div>

</div>
</div>


</div>
<h1>>>>>>>>>Sekian & Terimakasih<<<<<<<<</h1>
<footer class="bd-footer-content">
  
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
    <p class="component-author">
By The Jupyter Book Community
</p>

</div>

  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="assets/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="assets/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>